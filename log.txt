Using TensorFlow backend.
Loaded: 255 
['Preheat oven to 350 degrees F (175 degrees C). Line a baking sheet with a silicone baking mat or parchment paper. Put butter, white sugar, brown sugar, vanilla, baking soda, and salt in a bowl. Cream together with a mixer until butter clings to sides of bowl and is uniform in color, about 2 minutes. Mix in eggs 1 at a time, waiting until first is incorporated before adding second. Add 2 cups flour; mix on low speed until incorporated. (Dough will be very soft.) Divide dough roughly in half and transfer one half to a separate bowl. Mix remaining 1/2 cup flour into one half, then stir in semisweet chocolate chips until evenly distributed. Mix cocoa powder into other half, then stir in white chocolate chips until evenly distributed. Roll a tablespoon of each dough into a ball and tap lightly on counter to create a flat bottom (see assembly shots at left). Press flat sides together to form a larger ball, then flatten into a half dark, half light disk. Cut disk in half with a knife, cutting perpendicular to dough seam. Flip one half over and then firmly press halves back together. You should have a disk with 4 alternating quarters. Repeat with remaining dough. Transfer to baking sheet, spacing about 2 inches apart. Sprinkle with flaky sea salt. Bake until cookie edges start to turn golden brown, 10 to 12 minutes. Cool on sheet 10 minutes. Transfer to a wire rack to cool completely.']
['preheat oven to three hundred and fifty degrees one hundred and seventy-five degrees line baking sheet with silicone baking mat or parchment paper put butter white sugar brown sugar vanilla baking soda and salt in bowl cream together with mixer until butter clings to sides of bowl and is uniform in color about two minutes mix in eggs one at time waiting until first is incorporated before adding second add two cups flour mix on low speed until incorporated dough will be very soft divide dough roughly in half and transfer one half to separate bowl mix remaining twelve cup flour into one half then stir in semisweet chocolate chips until evenly distributed mix cocoa powder into other half then stir in white chocolate chips until evenly distributed roll tablespoon of each dough into ball and tap lightly on counter to create flat bottom see assembly shots at left press flat sides together to form larger ball then flatten into half dark half light disk cut disk in half with knife cutting perpendicular to dough seam flip one half over and then firmly press halves back together you should have disk with four alternating quarters repeat with remaining dough transfer to baking sheet spacing about two inches apart sprinkle with flaky sea salt bake until cookie edges start to turn golden brown ten to twelve minutes cool on sheet ten minutes transfer to wire rack to cool completely']
Vocabulary Size: 941
Descriptions: train=255
There was a recipe without directions --->>> My Favorite Chocolate Chip Cookie
Recipes: train=255
Vocabulary Size: 932
Description Length: 246
WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 246)          0                                            
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 246, 256)     238592      input_2[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 162)          0           input_1[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 246, 256)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 256)          41728       dropout_1[0][0]                  
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    
                                                                 lstm_1[0][0]                     
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 932)          239524      dense_2[0][0]                    
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 26634 samples, validate on 270 samples
Epoch 1/10
2019-04-11 10:53:31.143516: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA

Epoch 00001: val_loss improved from inf to 2.74491, saving model to model-ep001-loss4.117-val_loss2.745.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.74491 to 2.17765, saving model to model-ep002-loss2.557-val_loss2.178.h5
Epoch 3/10

Epoch 00003: val_loss did not improve from 2.17765
Epoch 4/10

Epoch 00004: val_loss improved from 2.17765 to 2.12090, saving model to model-ep004-loss1.830-val_loss2.121.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.12090 to 2.08262, saving model to model-ep005-loss1.648-val_loss2.083.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.08262
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.08262
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.08262
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.08262
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.08262
model-ep005-loss1.648-val_loss2.083.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.584928
BLEU-2: 0.444419
BLEU-3: 0.395699
BLEU-4: 0.301779
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 246)          0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 246, 256)     238592      input_4[0][0]                    
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 162)          0           input_3[0][0]                    
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 246, 256)     0           embedding_2[0][0]                
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256)          41728       dropout_3[0][0]                  
__________________________________________________________________________________________________
lstm_2 (LSTM)                   (None, 256)          525312      dropout_4[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256)          0           dense_4[0][0]                    
                                                                 lstm_2[0][0]                     
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 256)          65792       add_2[0][0]                      
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 932)          239524      dense_5[0][0]                    
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26634 samples, validate on 270 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.27242, saving model to model-ep001-loss4.157-val_loss2.272.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.27242 to 1.68744, saving model to model-ep002-loss2.533-val_loss1.687.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.68744 to 1.55641, saving model to model-ep003-loss2.091-val_loss1.556.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.55641 to 1.49739, saving model to model-ep004-loss1.845-val_loss1.497.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.49739 to 1.41913, saving model to model-ep005-loss1.667-val_loss1.419.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.41913
Epoch 7/10

Epoch 00007: val_loss improved from 1.41913 to 1.39056, saving model to model-ep007-loss1.397-val_loss1.391.h5
Epoch 8/10

Epoch 00008: val_loss improved from 1.39056 to 1.34295, saving model to model-ep008-loss1.282-val_loss1.343.h5
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.34295
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.34295
model-ep008-loss1.282-val_loss1.343.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.604583
BLEU-2: 0.456180
BLEU-3: 0.399620
BLEU-4: 0.296347
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 246)          0                                            
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 246, 256)     238592      input_6[0][0]                    
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 162)          0           input_5[0][0]                    
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 246, 256)     0           embedding_3[0][0]                
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 256)          41728       dropout_5[0][0]                  
__________________________________________________________________________________________________
lstm_3 (LSTM)                   (None, 256)          525312      dropout_6[0][0]                  
__________________________________________________________________________________________________
add_3 (Add)                     (None, 256)          0           dense_7[0][0]                    
                                                                 lstm_3[0][0]                     
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 256)          65792       add_3[0][0]                      
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 932)          239524      dense_8[0][0]                    
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26634 samples, validate on 270 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.89212, saving model to model-ep001-loss4.189-val_loss2.892.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.89212 to 2.09531, saving model to model-ep002-loss2.590-val_loss2.095.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.09531 to 1.87548, saving model to model-ep003-loss2.113-val_loss1.875.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.87548 to 1.78292, saving model to model-ep004-loss1.856-val_loss1.783.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.78292 to 1.71622, saving model to model-ep005-loss1.672-val_loss1.716.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.71622 to 1.69554, saving model to model-ep006-loss1.518-val_loss1.696.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.69554
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.69554
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.69554
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.69554
model-ep006-loss1.518-val_loss1.696.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.566769
BLEU-2: 0.430729
BLEU-3: 0.379043
BLEU-4: 0.288520
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_8 (InputLayer)            (None, 246)          0                                            
__________________________________________________________________________________________________
input_7 (InputLayer)            (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 246, 256)     238592      input_8[0][0]                    
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 162)          0           input_7[0][0]                    
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 246, 256)     0           embedding_4[0][0]                
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 256)          41728       dropout_7[0][0]                  
__________________________________________________________________________________________________
lstm_4 (LSTM)                   (None, 256)          525312      dropout_8[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 256)          0           dense_10[0][0]                   
                                                                 lstm_4[0][0]                     
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 256)          65792       add_4[0][0]                      
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 932)          239524      dense_11[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26634 samples, validate on 270 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.41117, saving model to model-ep001-loss4.117-val_loss2.411.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.41117 to 1.81622, saving model to model-ep002-loss2.520-val_loss1.816.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.81622 to 1.65511, saving model to model-ep003-loss2.053-val_loss1.655.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.65511 to 1.56689, saving model to model-ep004-loss1.804-val_loss1.567.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.56689 to 1.50632, saving model to model-ep005-loss1.623-val_loss1.506.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.50632
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.50632
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.50632
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.50632
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.50632
model-ep005-loss1.623-val_loss1.506.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.527217
BLEU-2: 0.394228
BLEU-3: 0.343916
BLEU-4: 0.254150
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_9 (InputLayer)            (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 246, 256)     238592      input_10[0][0]                   
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 162)          0           input_9[0][0]                    
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 246, 256)     0           embedding_5[0][0]                
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 256)          41728       dropout_9[0][0]                  
__________________________________________________________________________________________________
lstm_5 (LSTM)                   (None, 256)          525312      dropout_10[0][0]                 
__________________________________________________________________________________________________
add_5 (Add)                     (None, 256)          0           dense_13[0][0]                   
                                                                 lstm_5[0][0]                     
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 256)          65792       add_5[0][0]                      
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 932)          239524      dense_14[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 1.97251, saving model to model-ep001-loss4.170-val_loss1.973.h5
Epoch 2/10

Epoch 00002: val_loss improved from 1.97251 to 1.34616, saving model to model-ep002-loss2.584-val_loss1.346.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.34616 to 1.17886, saving model to model-ep003-loss2.094-val_loss1.179.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.17886 to 1.09319, saving model to model-ep004-loss1.844-val_loss1.093.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.09319 to 1.06780, saving model to model-ep005-loss1.666-val_loss1.068.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.06780 to 1.03883, saving model to model-ep006-loss1.517-val_loss1.039.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.03883 to 1.02290, saving model to model-ep007-loss1.389-val_loss1.023.h5
Epoch 8/10

Epoch 00008: val_loss improved from 1.02290 to 1.01039, saving model to model-ep008-loss1.273-val_loss1.010.h5
Epoch 9/10

Epoch 00009: val_loss improved from 1.01039 to 0.99985, saving model to model-ep009-loss1.160-val_loss1.000.h5
Epoch 10/10

Epoch 00010: val_loss improved from 0.99985 to 0.99202, saving model to model-ep010-loss1.063-val_loss0.992.h5
model-ep010-loss1.063-val_loss0.992.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.590030
BLEU-2: 0.452193
BLEU-3: 0.402798
BLEU-4: 0.309154
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_12 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_11 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 246, 256)     238592      input_12[0][0]                   
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 162)          0           input_11[0][0]                   
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 246, 256)     0           embedding_6[0][0]                
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 256)          41728       dropout_11[0][0]                 
__________________________________________________________________________________________________
lstm_6 (LSTM)                   (None, 256)          525312      dropout_12[0][0]                 
__________________________________________________________________________________________________
add_6 (Add)                     (None, 256)          0           dense_16[0][0]                   
                                                                 lstm_6[0][0]                     
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 256)          65792       add_6[0][0]                      
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 932)          239524      dense_17[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.91015, saving model to model-ep001-loss4.154-val_loss2.910.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.91015 to 2.26092, saving model to model-ep002-loss2.548-val_loss2.261.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.26092 to 2.09020, saving model to model-ep003-loss2.079-val_loss2.090.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.09020 to 1.95876, saving model to model-ep004-loss1.822-val_loss1.959.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 1.95876
Epoch 6/10

Epoch 00006: val_loss improved from 1.95876 to 1.93411, saving model to model-ep006-loss1.491-val_loss1.934.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.93411
Epoch 8/10

Epoch 00008: val_loss improved from 1.93411 to 1.91134, saving model to model-ep008-loss1.242-val_loss1.911.h5
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.91134
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.91134
model-ep008-loss1.242-val_loss1.911.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.569851
BLEU-2: 0.424083
BLEU-3: 0.372652
BLEU-4: 0.280622
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_14 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_13 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 246, 256)     238592      input_14[0][0]                   
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 162)          0           input_13[0][0]                   
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 246, 256)     0           embedding_7[0][0]                
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 256)          41728       dropout_13[0][0]                 
__________________________________________________________________________________________________
lstm_7 (LSTM)                   (None, 256)          525312      dropout_14[0][0]                 
__________________________________________________________________________________________________
add_7 (Add)                     (None, 256)          0           dense_19[0][0]                   
                                                                 lstm_7[0][0]                     
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 256)          65792       add_7[0][0]                      
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 932)          239524      dense_20[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.27906, saving model to model-ep001-loss4.132-val_loss2.279.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.27906 to 1.78017, saving model to model-ep002-loss2.548-val_loss1.780.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.78017 to 1.63580, saving model to model-ep003-loss2.083-val_loss1.636.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.63580 to 1.51782, saving model to model-ep004-loss1.833-val_loss1.518.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 1.51782
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.51782
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.51782
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.51782
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.51782
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.51782
model-ep004-loss1.833-val_loss1.518.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.595431
BLEU-2: 0.446910
BLEU-3: 0.395523
BLEU-4: 0.297331
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_16 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_15 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 246, 256)     238592      input_16[0][0]                   
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 162)          0           input_15[0][0]                   
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 246, 256)     0           embedding_8[0][0]                
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 256)          41728       dropout_15[0][0]                 
__________________________________________________________________________________________________
lstm_8 (LSTM)                   (None, 256)          525312      dropout_16[0][0]                 
__________________________________________________________________________________________________
add_8 (Add)                     (None, 256)          0           dense_22[0][0]                   
                                                                 lstm_8[0][0]                     
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 256)          65792       add_8[0][0]                      
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 932)          239524      dense_23[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 1.68689, saving model to model-ep001-loss4.182-val_loss1.687.h5
Epoch 2/10

Epoch 00002: val_loss improved from 1.68689 to 0.97419, saving model to model-ep002-loss2.576-val_loss0.974.h5
Epoch 3/10

Epoch 00003: val_loss improved from 0.97419 to 0.83732, saving model to model-ep003-loss2.101-val_loss0.837.h5
Epoch 4/10

Epoch 00004: val_loss improved from 0.83732 to 0.76450, saving model to model-ep004-loss1.836-val_loss0.764.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 0.76450
Epoch 6/10

Epoch 00006: val_loss improved from 0.76450 to 0.73714, saving model to model-ep006-loss1.502-val_loss0.737.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 0.73714
Epoch 8/10

Epoch 00008: val_loss did not improve from 0.73714
Epoch 9/10

Epoch 00009: val_loss did not improve from 0.73714
Epoch 10/10

Epoch 00010: val_loss did not improve from 0.73714
model-ep006-loss1.502-val_loss0.737.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.598405
BLEU-2: 0.450496
BLEU-3: 0.395191
BLEU-4: 0.297375
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_18 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_17 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 246, 256)     238592      input_18[0][0]                   
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 162)          0           input_17[0][0]                   
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 246, 256)     0           embedding_9[0][0]                
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 256)          41728       dropout_17[0][0]                 
__________________________________________________________________________________________________
lstm_9 (LSTM)                   (None, 256)          525312      dropout_18[0][0]                 
__________________________________________________________________________________________________
add_9 (Add)                     (None, 256)          0           dense_25[0][0]                   
                                                                 lstm_9[0][0]                     
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 256)          65792       add_9[0][0]                      
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 932)          239524      dense_26[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.08838, saving model to model-ep001-loss4.125-val_loss3.088.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.08838 to 2.60712, saving model to model-ep002-loss2.524-val_loss2.607.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.60712 to 2.43069, saving model to model-ep003-loss2.076-val_loss2.431.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.43069 to 2.38529, saving model to model-ep004-loss1.834-val_loss2.385.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.38529
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.38529
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.38529
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.38529
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.38529
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.38529
model-ep004-loss1.834-val_loss2.385.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.531040
BLEU-2: 0.399031
BLEU-3: 0.350855
BLEU-4: 0.266986
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_20 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_19 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 246, 256)     238592      input_20[0][0]                   
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 162)          0           input_19[0][0]                   
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 246, 256)     0           embedding_10[0][0]               
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 256)          41728       dropout_19[0][0]                 
__________________________________________________________________________________________________
lstm_10 (LSTM)                  (None, 256)          525312      dropout_20[0][0]                 
__________________________________________________________________________________________________
add_10 (Add)                    (None, 256)          0           dense_28[0][0]                   
                                                                 lstm_10[0][0]                    
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 256)          65792       add_10[0][0]                     
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 932)          239524      dense_29[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.58161, saving model to model-ep001-loss4.166-val_loss2.582.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.58161 to 2.04923, saving model to model-ep002-loss2.551-val_loss2.049.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.04923 to 1.86509, saving model to model-ep003-loss2.067-val_loss1.865.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.86509 to 1.83270, saving model to model-ep004-loss1.808-val_loss1.833.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 1.83270
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.83270
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.83270
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.83270
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.83270
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.83270
model-ep004-loss1.808-val_loss1.833.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.562218
BLEU-2: 0.419985
BLEU-3: 0.371509
BLEU-4: 0.278941
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_22 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_21 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 246, 256)     238592      input_22[0][0]                   
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 162)          0           input_21[0][0]                   
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 246, 256)     0           embedding_11[0][0]               
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 256)          41728       dropout_21[0][0]                 
__________________________________________________________________________________________________
lstm_11 (LSTM)                  (None, 256)          525312      dropout_22[0][0]                 
__________________________________________________________________________________________________
add_11 (Add)                    (None, 256)          0           dense_31[0][0]                   
                                                                 lstm_11[0][0]                    
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 256)          65792       add_11[0][0]                     
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 932)          239524      dense_32[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.61980, saving model to model-ep001-loss4.203-val_loss3.620.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.61980 to 3.05942, saving model to model-ep002-loss2.589-val_loss3.059.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.05942 to 2.92828, saving model to model-ep003-loss2.099-val_loss2.928.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.92828 to 2.87681, saving model to model-ep004-loss1.846-val_loss2.877.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.87681
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.87681
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.87681
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.87681
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.87681
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.87681
model-ep004-loss1.846-val_loss2.877.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.594531
BLEU-2: 0.448953
BLEU-3: 0.392299
BLEU-4: 0.291200
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_24 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_23 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 246, 256)     238592      input_24[0][0]                   
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 162)          0           input_23[0][0]                   
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 246, 256)     0           embedding_12[0][0]               
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 256)          41728       dropout_23[0][0]                 
__________________________________________________________________________________________________
lstm_12 (LSTM)                  (None, 256)          525312      dropout_24[0][0]                 
__________________________________________________________________________________________________
add_12 (Add)                    (None, 256)          0           dense_34[0][0]                   
                                                                 lstm_12[0][0]                    
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 256)          65792       add_12[0][0]                     
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 932)          239524      dense_35[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.23928, saving model to model-ep001-loss4.199-val_loss2.239.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.23928 to 1.59886, saving model to model-ep002-loss2.628-val_loss1.599.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.59886 to 1.33110, saving model to model-ep003-loss2.136-val_loss1.331.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.33110 to 1.26587, saving model to model-ep004-loss1.874-val_loss1.266.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.26587 to 1.21011, saving model to model-ep005-loss1.693-val_loss1.210.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.21011 to 1.19433, saving model to model-ep006-loss1.552-val_loss1.194.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.19433 to 1.11682, saving model to model-ep007-loss1.429-val_loss1.117.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.11682
Epoch 9/10

Epoch 00009: val_loss improved from 1.11682 to 1.10689, saving model to model-ep009-loss1.215-val_loss1.107.h5
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.10689
model-ep009-loss1.215-val_loss1.107.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.582971
BLEU-2: 0.431111
BLEU-3: 0.379846
BLEU-4: 0.282775
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_26 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_25 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 246, 256)     238592      input_26[0][0]                   
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 162)          0           input_25[0][0]                   
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 246, 256)     0           embedding_13[0][0]               
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 256)          41728       dropout_25[0][0]                 
__________________________________________________________________________________________________
lstm_13 (LSTM)                  (None, 256)          525312      dropout_26[0][0]                 
__________________________________________________________________________________________________
add_13 (Add)                    (None, 256)          0           dense_37[0][0]                   
                                                                 lstm_13[0][0]                    
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 256)          65792       add_13[0][0]                     
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 932)          239524      dense_38[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.59921, saving model to model-ep001-loss4.163-val_loss2.599.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.59921 to 1.84862, saving model to model-ep002-loss2.541-val_loss1.849.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.84862 to 1.75197, saving model to model-ep003-loss2.083-val_loss1.752.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.75197 to 1.59249, saving model to model-ep004-loss1.839-val_loss1.592.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.59249 to 1.46369, saving model to model-ep005-loss1.664-val_loss1.464.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.46369 to 1.46205, saving model to model-ep006-loss1.516-val_loss1.462.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.46205 to 1.44436, saving model to model-ep007-loss1.390-val_loss1.444.h5
Epoch 8/10

Epoch 00008: val_loss improved from 1.44436 to 1.41143, saving model to model-ep008-loss1.267-val_loss1.411.h5
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.41143
Epoch 10/10

Epoch 00010: val_loss improved from 1.41143 to 1.40834, saving model to model-ep010-loss1.073-val_loss1.408.h5
model-ep010-loss1.073-val_loss1.408.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.600947
BLEU-2: 0.457395
BLEU-3: 0.404742
BLEU-4: 0.305730
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_28 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_27 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 246, 256)     238592      input_28[0][0]                   
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 162)          0           input_27[0][0]                   
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 246, 256)     0           embedding_14[0][0]               
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 256)          41728       dropout_27[0][0]                 
__________________________________________________________________________________________________
lstm_14 (LSTM)                  (None, 256)          525312      dropout_28[0][0]                 
__________________________________________________________________________________________________
add_14 (Add)                    (None, 256)          0           dense_40[0][0]                   
                                                                 lstm_14[0][0]                    
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 256)          65792       add_14[0][0]                     
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 932)          239524      dense_41[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.16936, saving model to model-ep001-loss4.253-val_loss3.169.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.16936 to 2.63482, saving model to model-ep002-loss2.635-val_loss2.635.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.63482 to 2.37338, saving model to model-ep003-loss2.135-val_loss2.373.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.37338 to 2.33830, saving model to model-ep004-loss1.870-val_loss2.338.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.33830 to 2.31178, saving model to model-ep005-loss1.686-val_loss2.312.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.31178 to 2.28714, saving model to model-ep006-loss1.540-val_loss2.287.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.28714
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.28714
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.28714
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.28714
model-ep006-loss1.540-val_loss2.287.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.560346
BLEU-2: 0.427750
BLEU-3: 0.379361
BLEU-4: 0.289568
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_30 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_29 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 246, 256)     238592      input_30[0][0]                   
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 162)          0           input_29[0][0]                   
__________________________________________________________________________________________________
dropout_30 (Dropout)            (None, 246, 256)     0           embedding_15[0][0]               
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 256)          41728       dropout_29[0][0]                 
__________________________________________________________________________________________________
lstm_15 (LSTM)                  (None, 256)          525312      dropout_30[0][0]                 
__________________________________________________________________________________________________
add_15 (Add)                    (None, 256)          0           dense_43[0][0]                   
                                                                 lstm_15[0][0]                    
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 256)          65792       add_15[0][0]                     
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 932)          239524      dense_44[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.38961, saving model to model-ep001-loss4.153-val_loss3.390.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.38961 to 2.92097, saving model to model-ep002-loss2.548-val_loss2.921.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.92097 to 2.82161, saving model to model-ep003-loss2.073-val_loss2.822.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.82161 to 2.79913, saving model to model-ep004-loss1.820-val_loss2.799.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.79913
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.79913
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.79913
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.79913
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.79913
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.79913
model-ep004-loss1.820-val_loss2.799.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.587214
BLEU-2: 0.439882
BLEU-3: 0.391905
BLEU-4: 0.294596
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_32 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_31 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 246, 256)     238592      input_32[0][0]                   
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 162)          0           input_31[0][0]                   
__________________________________________________________________________________________________
dropout_32 (Dropout)            (None, 246, 256)     0           embedding_16[0][0]               
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 256)          41728       dropout_31[0][0]                 
__________________________________________________________________________________________________
lstm_16 (LSTM)                  (None, 256)          525312      dropout_32[0][0]                 
__________________________________________________________________________________________________
add_16 (Add)                    (None, 256)          0           dense_46[0][0]                   
                                                                 lstm_16[0][0]                    
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 256)          65792       add_16[0][0]                     
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 932)          239524      dense_47[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.18865, saving model to model-ep001-loss4.149-val_loss3.189.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.18865 to 2.51654, saving model to model-ep002-loss2.521-val_loss2.517.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.51654 to 2.39867, saving model to model-ep003-loss2.064-val_loss2.399.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.39867 to 2.34239, saving model to model-ep004-loss1.810-val_loss2.342.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.34239
Epoch 6/10

Epoch 00006: val_loss improved from 2.34239 to 2.28482, saving model to model-ep006-loss1.479-val_loss2.285.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.28482
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.28482
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.28482
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.28482
model-ep006-loss1.479-val_loss2.285.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.573375
BLEU-2: 0.437185
BLEU-3: 0.389066
BLEU-4: 0.296415
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_34 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_33 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 246, 256)     238592      input_34[0][0]                   
__________________________________________________________________________________________________
dropout_33 (Dropout)            (None, 162)          0           input_33[0][0]                   
__________________________________________________________________________________________________
dropout_34 (Dropout)            (None, 246, 256)     0           embedding_17[0][0]               
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 256)          41728       dropout_33[0][0]                 
__________________________________________________________________________________________________
lstm_17 (LSTM)                  (None, 256)          525312      dropout_34[0][0]                 
__________________________________________________________________________________________________
add_17 (Add)                    (None, 256)          0           dense_49[0][0]                   
                                                                 lstm_17[0][0]                    
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 256)          65792       add_17[0][0]                     
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 932)          239524      dense_50[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.05651, saving model to model-ep001-loss4.128-val_loss3.057.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.05651 to 2.49194, saving model to model-ep002-loss2.521-val_loss2.492.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.49194 to 2.31211, saving model to model-ep003-loss2.059-val_loss2.312.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.31211 to 2.28805, saving model to model-ep004-loss1.821-val_loss2.288.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.28805
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.28805
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.28805
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.28805
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.28805
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.28805
model-ep004-loss1.821-val_loss2.288.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.592811
BLEU-2: 0.449937
BLEU-3: 0.400580
BLEU-4: 0.303679
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_36 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_35 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 246, 256)     238592      input_36[0][0]                   
__________________________________________________________________________________________________
dropout_35 (Dropout)            (None, 162)          0           input_35[0][0]                   
__________________________________________________________________________________________________
dropout_36 (Dropout)            (None, 246, 256)     0           embedding_18[0][0]               
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 256)          41728       dropout_35[0][0]                 
__________________________________________________________________________________________________
lstm_18 (LSTM)                  (None, 256)          525312      dropout_36[0][0]                 
__________________________________________________________________________________________________
add_18 (Add)                    (None, 256)          0           dense_52[0][0]                   
                                                                 lstm_18[0][0]                    
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 256)          65792       add_18[0][0]                     
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 932)          239524      dense_53[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.39765, saving model to model-ep001-loss4.143-val_loss2.398.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.39765 to 1.80504, saving model to model-ep002-loss2.565-val_loss1.805.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.80504 to 1.63277, saving model to model-ep003-loss2.072-val_loss1.633.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.63277 to 1.58322, saving model to model-ep004-loss1.811-val_loss1.583.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 1.58322
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.58322
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.58322
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.58322
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.58322
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.58322
model-ep004-loss1.811-val_loss1.583.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.591295
BLEU-2: 0.446418
BLEU-3: 0.396152
BLEU-4: 0.294623
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_38 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_37 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 246, 256)     238592      input_38[0][0]                   
__________________________________________________________________________________________________
dropout_37 (Dropout)            (None, 162)          0           input_37[0][0]                   
__________________________________________________________________________________________________
dropout_38 (Dropout)            (None, 246, 256)     0           embedding_19[0][0]               
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 256)          41728       dropout_37[0][0]                 
__________________________________________________________________________________________________
lstm_19 (LSTM)                  (None, 256)          525312      dropout_38[0][0]                 
__________________________________________________________________________________________________
add_19 (Add)                    (None, 256)          0           dense_55[0][0]                   
                                                                 lstm_19[0][0]                    
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 256)          65792       add_19[0][0]                     
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 932)          239524      dense_56[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.81142, saving model to model-ep001-loss4.094-val_loss2.811.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.81142 to 2.32243, saving model to model-ep002-loss2.513-val_loss2.322.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.32243 to 2.23395, saving model to model-ep003-loss2.061-val_loss2.234.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.23395 to 2.16985, saving model to model-ep004-loss1.816-val_loss2.170.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.16985
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.16985
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.16985
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.16985
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.16985
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.16985
model-ep004-loss1.816-val_loss2.170.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.505633
BLEU-2: 0.370199
BLEU-3: 0.319758
BLEU-4: 0.237593
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_40 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_39 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 246, 256)     238592      input_40[0][0]                   
__________________________________________________________________________________________________
dropout_39 (Dropout)            (None, 162)          0           input_39[0][0]                   
__________________________________________________________________________________________________
dropout_40 (Dropout)            (None, 246, 256)     0           embedding_20[0][0]               
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 256)          41728       dropout_39[0][0]                 
__________________________________________________________________________________________________
lstm_20 (LSTM)                  (None, 256)          525312      dropout_40[0][0]                 
__________________________________________________________________________________________________
add_20 (Add)                    (None, 256)          0           dense_58[0][0]                   
                                                                 lstm_20[0][0]                    
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 256)          65792       add_20[0][0]                     
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 932)          239524      dense_59[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.56476, saving model to model-ep001-loss4.120-val_loss2.565.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.56476 to 1.99419, saving model to model-ep002-loss2.536-val_loss1.994.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.99419 to 1.74883, saving model to model-ep003-loss2.066-val_loss1.749.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.74883 to 1.66549, saving model to model-ep004-loss1.820-val_loss1.665.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.66549 to 1.61861, saving model to model-ep005-loss1.648-val_loss1.619.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.61861
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.61861
Epoch 8/10

Epoch 00008: val_loss improved from 1.61861 to 1.59854, saving model to model-ep008-loss1.259-val_loss1.599.h5
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.59854
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.59854
model-ep008-loss1.259-val_loss1.599.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.610675
BLEU-2: 0.464369
BLEU-3: 0.412332
BLEU-4: 0.313741
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_42 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_41 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 246, 256)     238592      input_42[0][0]                   
__________________________________________________________________________________________________
dropout_41 (Dropout)            (None, 162)          0           input_41[0][0]                   
__________________________________________________________________________________________________
dropout_42 (Dropout)            (None, 246, 256)     0           embedding_21[0][0]               
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 256)          41728       dropout_41[0][0]                 
__________________________________________________________________________________________________
lstm_21 (LSTM)                  (None, 256)          525312      dropout_42[0][0]                 
__________________________________________________________________________________________________
add_21 (Add)                    (None, 256)          0           dense_61[0][0]                   
                                                                 lstm_21[0][0]                    
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 256)          65792       add_21[0][0]                     
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 932)          239524      dense_62[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.01718, saving model to model-ep001-loss4.182-val_loss2.017.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.01718 to 1.50170, saving model to model-ep002-loss2.552-val_loss1.502.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.50170 to 1.40957, saving model to model-ep003-loss2.078-val_loss1.410.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.40957 to 1.30007, saving model to model-ep004-loss1.826-val_loss1.300.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.30007 to 1.28240, saving model to model-ep005-loss1.640-val_loss1.282.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.28240 to 1.25306, saving model to model-ep006-loss1.493-val_loss1.253.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.25306
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.25306
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.25306
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.25306
model-ep006-loss1.493-val_loss1.253.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.564320
BLEU-2: 0.425322
BLEU-3: 0.375181
BLEU-4: 0.284122
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_44 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_43 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 246, 256)     238592      input_44[0][0]                   
__________________________________________________________________________________________________
dropout_43 (Dropout)            (None, 162)          0           input_43[0][0]                   
__________________________________________________________________________________________________
dropout_44 (Dropout)            (None, 246, 256)     0           embedding_22[0][0]               
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 256)          41728       dropout_43[0][0]                 
__________________________________________________________________________________________________
lstm_22 (LSTM)                  (None, 256)          525312      dropout_44[0][0]                 
__________________________________________________________________________________________________
add_22 (Add)                    (None, 256)          0           dense_64[0][0]                   
                                                                 lstm_22[0][0]                    
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 256)          65792       add_22[0][0]                     
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 932)          239524      dense_65[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.96251, saving model to model-ep001-loss4.217-val_loss2.963.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.96251 to 2.31136, saving model to model-ep002-loss2.543-val_loss2.311.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.31136 to 2.13165, saving model to model-ep003-loss2.069-val_loss2.132.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.13165 to 2.05416, saving model to model-ep004-loss1.821-val_loss2.054.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.05416 to 2.02563, saving model to model-ep005-loss1.640-val_loss2.026.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.02563 to 2.02227, saving model to model-ep006-loss1.488-val_loss2.022.h5
Epoch 7/10

Epoch 00007: val_loss improved from 2.02227 to 2.00247, saving model to model-ep007-loss1.370-val_loss2.002.h5
Epoch 8/10

Epoch 00008: val_loss improved from 2.00247 to 1.97451, saving model to model-ep008-loss1.249-val_loss1.975.h5
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.97451
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.97451
model-ep008-loss1.249-val_loss1.975.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.556916
BLEU-2: 0.419231
BLEU-3: 0.368364
BLEU-4: 0.278203
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_46 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_45 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 246, 256)     238592      input_46[0][0]                   
__________________________________________________________________________________________________
dropout_45 (Dropout)            (None, 162)          0           input_45[0][0]                   
__________________________________________________________________________________________________
dropout_46 (Dropout)            (None, 246, 256)     0           embedding_23[0][0]               
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 256)          41728       dropout_45[0][0]                 
__________________________________________________________________________________________________
lstm_23 (LSTM)                  (None, 256)          525312      dropout_46[0][0]                 
__________________________________________________________________________________________________
add_23 (Add)                    (None, 256)          0           dense_67[0][0]                   
                                                                 lstm_23[0][0]                    
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 256)          65792       add_23[0][0]                     
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 932)          239524      dense_68[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.18746, saving model to model-ep001-loss4.188-val_loss3.187.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.18746 to 2.72470, saving model to model-ep002-loss2.566-val_loss2.725.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.72470 to 2.51985, saving model to model-ep003-loss2.096-val_loss2.520.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.51985 to 2.50890, saving model to model-ep004-loss1.846-val_loss2.509.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.50890 to 2.43538, saving model to model-ep005-loss1.667-val_loss2.435.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.43538
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.43538
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.43538
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.43538
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.43538
model-ep005-loss1.667-val_loss2.435.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.550929
BLEU-2: 0.407353
BLEU-3: 0.354922
BLEU-4: 0.263362
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_48 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_47 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 246, 256)     238592      input_48[0][0]                   
__________________________________________________________________________________________________
dropout_47 (Dropout)            (None, 162)          0           input_47[0][0]                   
__________________________________________________________________________________________________
dropout_48 (Dropout)            (None, 246, 256)     0           embedding_24[0][0]               
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 256)          41728       dropout_47[0][0]                 
__________________________________________________________________________________________________
lstm_24 (LSTM)                  (None, 256)          525312      dropout_48[0][0]                 
__________________________________________________________________________________________________
add_24 (Add)                    (None, 256)          0           dense_70[0][0]                   
                                                                 lstm_24[0][0]                    
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 256)          65792       add_24[0][0]                     
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 932)          239524      dense_71[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 4.72218, saving model to model-ep001-loss4.198-val_loss4.722.h5
Epoch 2/10

Epoch 00002: val_loss improved from 4.72218 to 4.56192, saving model to model-ep002-loss2.569-val_loss4.562.h5
Epoch 3/10

Epoch 00003: val_loss improved from 4.56192 to 4.33591, saving model to model-ep003-loss2.100-val_loss4.336.h5
Epoch 4/10

Epoch 00004: val_loss improved from 4.33591 to 4.30128, saving model to model-ep004-loss1.852-val_loss4.301.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 4.30128
Epoch 6/10

Epoch 00006: val_loss did not improve from 4.30128
Epoch 7/10

Epoch 00007: val_loss did not improve from 4.30128
Epoch 8/10

Epoch 00008: val_loss did not improve from 4.30128
Epoch 9/10

Epoch 00009: val_loss did not improve from 4.30128
Epoch 10/10

Epoch 00010: val_loss did not improve from 4.30128
model-ep004-loss1.852-val_loss4.301.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.579555
BLEU-2: 0.435183
BLEU-3: 0.381464
BLEU-4: 0.282001
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_50 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_49 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 246, 256)     238592      input_50[0][0]                   
__________________________________________________________________________________________________
dropout_49 (Dropout)            (None, 162)          0           input_49[0][0]                   
__________________________________________________________________________________________________
dropout_50 (Dropout)            (None, 246, 256)     0           embedding_25[0][0]               
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 256)          41728       dropout_49[0][0]                 
__________________________________________________________________________________________________
lstm_25 (LSTM)                  (None, 256)          525312      dropout_50[0][0]                 
__________________________________________________________________________________________________
add_25 (Add)                    (None, 256)          0           dense_73[0][0]                   
                                                                 lstm_25[0][0]                    
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 256)          65792       add_25[0][0]                     
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 932)          239524      dense_74[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.82264, saving model to model-ep001-loss4.105-val_loss3.823.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.82264 to 3.54454, saving model to model-ep002-loss2.504-val_loss3.545.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.54454 to 3.44173, saving model to model-ep003-loss2.046-val_loss3.442.h5
Epoch 4/10

Epoch 00004: val_loss did not improve from 3.44173
Epoch 5/10

Epoch 00005: val_loss did not improve from 3.44173
Epoch 6/10

Epoch 00006: val_loss did not improve from 3.44173
Epoch 7/10

Epoch 00007: val_loss did not improve from 3.44173
Epoch 8/10

Epoch 00008: val_loss did not improve from 3.44173
Epoch 9/10

Epoch 00009: val_loss did not improve from 3.44173
Epoch 10/10

Epoch 00010: val_loss did not improve from 3.44173
model-ep003-loss2.046-val_loss3.442.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.574800
BLEU-2: 0.432817
BLEU-3: 0.380148
BLEU-4: 0.280524
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_52 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_51 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 246, 256)     238592      input_52[0][0]                   
__________________________________________________________________________________________________
dropout_51 (Dropout)            (None, 162)          0           input_51[0][0]                   
__________________________________________________________________________________________________
dropout_52 (Dropout)            (None, 246, 256)     0           embedding_26[0][0]               
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 256)          41728       dropout_51[0][0]                 
__________________________________________________________________________________________________
lstm_26 (LSTM)                  (None, 256)          525312      dropout_52[0][0]                 
__________________________________________________________________________________________________
add_26 (Add)                    (None, 256)          0           dense_76[0][0]                   
                                                                 lstm_26[0][0]                    
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 256)          65792       add_26[0][0]                     
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 932)          239524      dense_77[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.55277, saving model to model-ep001-loss4.110-val_loss3.553.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.55277 to 2.94417, saving model to model-ep002-loss2.527-val_loss2.944.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.94417 to 2.75444, saving model to model-ep003-loss2.059-val_loss2.754.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.75444 to 2.71565, saving model to model-ep004-loss1.818-val_loss2.716.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.71565 to 2.71039, saving model to model-ep005-loss1.634-val_loss2.710.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.71039 to 2.70115, saving model to model-ep006-loss1.490-val_loss2.701.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.70115
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.70115
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.70115
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.70115
model-ep006-loss1.490-val_loss2.701.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.528763
BLEU-2: 0.398314
BLEU-3: 0.351451
BLEU-4: 0.266049
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_54 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_53 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 246, 256)     238592      input_54[0][0]                   
__________________________________________________________________________________________________
dropout_53 (Dropout)            (None, 162)          0           input_53[0][0]                   
__________________________________________________________________________________________________
dropout_54 (Dropout)            (None, 246, 256)     0           embedding_27[0][0]               
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 256)          41728       dropout_53[0][0]                 
__________________________________________________________________________________________________
lstm_27 (LSTM)                  (None, 256)          525312      dropout_54[0][0]                 
__________________________________________________________________________________________________
add_27 (Add)                    (None, 256)          0           dense_79[0][0]                   
                                                                 lstm_27[0][0]                    
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 256)          65792       add_27[0][0]                     
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 932)          239524      dense_80[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.93298, saving model to model-ep001-loss4.144-val_loss2.933.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.93298 to 2.34921, saving model to model-ep002-loss2.579-val_loss2.349.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.34921 to 2.13698, saving model to model-ep003-loss2.132-val_loss2.137.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.13698 to 2.06420, saving model to model-ep004-loss1.876-val_loss2.064.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.06420 to 2.05199, saving model to model-ep005-loss1.698-val_loss2.052.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.05199 to 2.05069, saving model to model-ep006-loss1.555-val_loss2.051.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.05069
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.05069
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.05069
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.05069
model-ep006-loss1.555-val_loss2.051.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.585789
BLEU-2: 0.436774
BLEU-3: 0.389439
BLEU-4: 0.292397
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_56 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_55 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 246, 256)     238592      input_56[0][0]                   
__________________________________________________________________________________________________
dropout_55 (Dropout)            (None, 162)          0           input_55[0][0]                   
__________________________________________________________________________________________________
dropout_56 (Dropout)            (None, 246, 256)     0           embedding_28[0][0]               
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 256)          41728       dropout_55[0][0]                 
__________________________________________________________________________________________________
lstm_28 (LSTM)                  (None, 256)          525312      dropout_56[0][0]                 
__________________________________________________________________________________________________
add_28 (Add)                    (None, 256)          0           dense_82[0][0]                   
                                                                 lstm_28[0][0]                    
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 256)          65792       add_28[0][0]                     
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 932)          239524      dense_83[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.56036, saving model to model-ep001-loss4.116-val_loss2.560.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.56036 to 2.10442, saving model to model-ep002-loss2.510-val_loss2.104.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.10442 to 1.96033, saving model to model-ep003-loss2.055-val_loss1.960.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.96033 to 1.88929, saving model to model-ep004-loss1.818-val_loss1.889.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 1.88929
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.88929
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.88929
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.88929
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.88929
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.88929
model-ep004-loss1.818-val_loss1.889.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.595392
BLEU-2: 0.455593
BLEU-3: 0.405855
BLEU-4: 0.310073
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_58 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_57 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 246, 256)     238592      input_58[0][0]                   
__________________________________________________________________________________________________
dropout_57 (Dropout)            (None, 162)          0           input_57[0][0]                   
__________________________________________________________________________________________________
dropout_58 (Dropout)            (None, 246, 256)     0           embedding_29[0][0]               
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 256)          41728       dropout_57[0][0]                 
__________________________________________________________________________________________________
lstm_29 (LSTM)                  (None, 256)          525312      dropout_58[0][0]                 
__________________________________________________________________________________________________
add_29 (Add)                    (None, 256)          0           dense_85[0][0]                   
                                                                 lstm_29[0][0]                    
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 256)          65792       add_29[0][0]                     
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 932)          239524      dense_86[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.69389, saving model to model-ep001-loss4.173-val_loss3.694.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.69389 to 3.30755, saving model to model-ep002-loss2.564-val_loss3.308.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.30755 to 3.13383, saving model to model-ep003-loss2.106-val_loss3.134.h5
Epoch 4/10

Epoch 00004: val_loss improved from 3.13383 to 3.10756, saving model to model-ep004-loss1.864-val_loss3.108.h5
Epoch 5/10

Epoch 00005: val_loss improved from 3.10756 to 3.08128, saving model to model-ep005-loss1.689-val_loss3.081.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 3.08128
Epoch 7/10

Epoch 00007: val_loss did not improve from 3.08128
Epoch 8/10

Epoch 00008: val_loss did not improve from 3.08128
Epoch 9/10

Epoch 00009: val_loss did not improve from 3.08128
Epoch 10/10

Epoch 00010: val_loss did not improve from 3.08128
model-ep005-loss1.689-val_loss3.081.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.590779
BLEU-2: 0.446747
BLEU-3: 0.397191
BLEU-4: 0.302040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_60 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_59 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 246, 256)     238592      input_60[0][0]                   
__________________________________________________________________________________________________
dropout_59 (Dropout)            (None, 162)          0           input_59[0][0]                   
__________________________________________________________________________________________________
dropout_60 (Dropout)            (None, 246, 256)     0           embedding_30[0][0]               
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 256)          41728       dropout_59[0][0]                 
__________________________________________________________________________________________________
lstm_30 (LSTM)                  (None, 256)          525312      dropout_60[0][0]                 
__________________________________________________________________________________________________
add_30 (Add)                    (None, 256)          0           dense_88[0][0]                   
                                                                 lstm_30[0][0]                    
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 256)          65792       add_30[0][0]                     
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 932)          239524      dense_89[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.59302, saving model to model-ep001-loss4.193-val_loss3.593.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.59302 to 3.14643, saving model to model-ep002-loss2.598-val_loss3.146.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.14643 to 2.94700, saving model to model-ep003-loss2.115-val_loss2.947.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.94700 to 2.85000, saving model to model-ep004-loss1.859-val_loss2.850.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.85000
Epoch 6/10

Epoch 00006: val_loss improved from 2.85000 to 2.81999, saving model to model-ep006-loss1.533-val_loss2.820.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.81999
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.81999
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.81999
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.81999
model-ep006-loss1.533-val_loss2.820.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.592518
BLEU-2: 0.454416
BLEU-3: 0.405345
BLEU-4: 0.310780
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_62 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_61 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 246, 256)     238592      input_62[0][0]                   
__________________________________________________________________________________________________
dropout_61 (Dropout)            (None, 162)          0           input_61[0][0]                   
__________________________________________________________________________________________________
dropout_62 (Dropout)            (None, 246, 256)     0           embedding_31[0][0]               
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 256)          41728       dropout_61[0][0]                 
__________________________________________________________________________________________________
lstm_31 (LSTM)                  (None, 256)          525312      dropout_62[0][0]                 
__________________________________________________________________________________________________
add_31 (Add)                    (None, 256)          0           dense_91[0][0]                   
                                                                 lstm_31[0][0]                    
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 256)          65792       add_31[0][0]                     
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 932)          239524      dense_92[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.60551, saving model to model-ep001-loss4.134-val_loss2.606.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.60551 to 1.97720, saving model to model-ep002-loss2.521-val_loss1.977.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.97720 to 1.81370, saving model to model-ep003-loss2.053-val_loss1.814.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.81370 to 1.73885, saving model to model-ep004-loss1.803-val_loss1.739.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.73885 to 1.62635, saving model to model-ep005-loss1.625-val_loss1.626.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.62635
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.62635
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.62635
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.62635
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.62635
model-ep005-loss1.625-val_loss1.626.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.592119
BLEU-2: 0.449362
BLEU-3: 0.399594
BLEU-4: 0.301905
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_64 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_63 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 246, 256)     238592      input_64[0][0]                   
__________________________________________________________________________________________________
dropout_63 (Dropout)            (None, 162)          0           input_63[0][0]                   
__________________________________________________________________________________________________
dropout_64 (Dropout)            (None, 246, 256)     0           embedding_32[0][0]               
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 256)          41728       dropout_63[0][0]                 
__________________________________________________________________________________________________
lstm_32 (LSTM)                  (None, 256)          525312      dropout_64[0][0]                 
__________________________________________________________________________________________________
add_32 (Add)                    (None, 256)          0           dense_94[0][0]                   
                                                                 lstm_32[0][0]                    
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 256)          65792       add_32[0][0]                     
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 932)          239524      dense_95[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.24337, saving model to model-ep001-loss4.144-val_loss3.243.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.24337 to 2.60001, saving model to model-ep002-loss2.550-val_loss2.600.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.60001 to 2.36255, saving model to model-ep003-loss2.066-val_loss2.363.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.36255 to 2.27506, saving model to model-ep004-loss1.820-val_loss2.275.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.27506 to 2.22143, saving model to model-ep005-loss1.639-val_loss2.221.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.22143 to 2.17303, saving model to model-ep006-loss1.486-val_loss2.173.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.17303
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.17303
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.17303
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.17303
model-ep006-loss1.486-val_loss2.173.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.586482
BLEU-2: 0.448120
BLEU-3: 0.397592
BLEU-4: 0.304734
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_66 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_65 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 246, 256)     238592      input_66[0][0]                   
__________________________________________________________________________________________________
dropout_65 (Dropout)            (None, 162)          0           input_65[0][0]                   
__________________________________________________________________________________________________
dropout_66 (Dropout)            (None, 246, 256)     0           embedding_33[0][0]               
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 256)          41728       dropout_65[0][0]                 
__________________________________________________________________________________________________
lstm_33 (LSTM)                  (None, 256)          525312      dropout_66[0][0]                 
__________________________________________________________________________________________________
add_33 (Add)                    (None, 256)          0           dense_97[0][0]                   
                                                                 lstm_33[0][0]                    
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 256)          65792       add_33[0][0]                     
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 932)          239524      dense_98[0][0]                   
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.78193, saving model to model-ep001-loss4.099-val_loss2.782.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.78193 to 2.28318, saving model to model-ep002-loss2.501-val_loss2.283.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.28318 to 2.19848, saving model to model-ep003-loss2.046-val_loss2.198.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.19848 to 2.14694, saving model to model-ep004-loss1.801-val_loss2.147.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.14694
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.14694
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.14694
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.14694
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.14694
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.14694
model-ep004-loss1.801-val_loss2.147.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.584479
BLEU-2: 0.438787
BLEU-3: 0.384203
BLEU-4: 0.285274
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_68 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_67 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 246, 256)     238592      input_68[0][0]                   
__________________________________________________________________________________________________
dropout_67 (Dropout)            (None, 162)          0           input_67[0][0]                   
__________________________________________________________________________________________________
dropout_68 (Dropout)            (None, 246, 256)     0           embedding_34[0][0]               
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 256)          41728       dropout_67[0][0]                 
__________________________________________________________________________________________________
lstm_34 (LSTM)                  (None, 256)          525312      dropout_68[0][0]                 
__________________________________________________________________________________________________
add_34 (Add)                    (None, 256)          0           dense_100[0][0]                  
                                                                 lstm_34[0][0]                    
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 256)          65792       add_34[0][0]                     
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 932)          239524      dense_101[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.86563, saving model to model-ep001-loss4.124-val_loss2.866.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.86563 to 2.30926, saving model to model-ep002-loss2.543-val_loss2.309.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.30926 to 2.19296, saving model to model-ep003-loss2.085-val_loss2.193.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.19296 to 2.10486, saving model to model-ep004-loss1.837-val_loss2.105.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.10486 to 2.03107, saving model to model-ep005-loss1.657-val_loss2.031.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.03107
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.03107
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.03107
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.03107
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.03107
model-ep005-loss1.657-val_loss2.031.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.607502
BLEU-2: 0.460624
BLEU-3: 0.409875
BLEU-4: 0.311171
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_70 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_69 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 246, 256)     238592      input_70[0][0]                   
__________________________________________________________________________________________________
dropout_69 (Dropout)            (None, 162)          0           input_69[0][0]                   
__________________________________________________________________________________________________
dropout_70 (Dropout)            (None, 246, 256)     0           embedding_35[0][0]               
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 256)          41728       dropout_69[0][0]                 
__________________________________________________________________________________________________
lstm_35 (LSTM)                  (None, 256)          525312      dropout_70[0][0]                 
__________________________________________________________________________________________________
add_35 (Add)                    (None, 256)          0           dense_103[0][0]                  
                                                                 lstm_35[0][0]                    
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 256)          65792       add_35[0][0]                     
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 932)          239524      dense_104[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.88056, saving model to model-ep001-loss4.111-val_loss2.881.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.88056 to 2.24779, saving model to model-ep002-loss2.518-val_loss2.248.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.24779 to 2.06599, saving model to model-ep003-loss2.060-val_loss2.066.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.06599 to 1.98535, saving model to model-ep004-loss1.813-val_loss1.985.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.98535 to 1.96254, saving model to model-ep005-loss1.629-val_loss1.963.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.96254
Epoch 7/10

Epoch 00007: val_loss improved from 1.96254 to 1.90537, saving model to model-ep007-loss1.354-val_loss1.905.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.90537
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.90537
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.90537
model-ep007-loss1.354-val_loss1.905.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.592962
BLEU-2: 0.450414
BLEU-3: 0.397545
BLEU-4: 0.299489
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_72 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_71 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 246, 256)     238592      input_72[0][0]                   
__________________________________________________________________________________________________
dropout_71 (Dropout)            (None, 162)          0           input_71[0][0]                   
__________________________________________________________________________________________________
dropout_72 (Dropout)            (None, 246, 256)     0           embedding_36[0][0]               
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 256)          41728       dropout_71[0][0]                 
__________________________________________________________________________________________________
lstm_36 (LSTM)                  (None, 256)          525312      dropout_72[0][0]                 
__________________________________________________________________________________________________
add_36 (Add)                    (None, 256)          0           dense_106[0][0]                  
                                                                 lstm_36[0][0]                    
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 256)          65792       add_36[0][0]                     
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 932)          239524      dense_107[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.45366, saving model to model-ep001-loss4.181-val_loss3.454.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.45366 to 2.87663, saving model to model-ep002-loss2.610-val_loss2.877.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.87663 to 2.74340, saving model to model-ep003-loss2.122-val_loss2.743.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.74340 to 2.62325, saving model to model-ep004-loss1.869-val_loss2.623.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.62325 to 2.62320, saving model to model-ep005-loss1.691-val_loss2.623.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.62320
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.62320
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.62320
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.62320
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.62320
model-ep005-loss1.691-val_loss2.623.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.585378
BLEU-2: 0.443618
BLEU-3: 0.394791
BLEU-4: 0.300185
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_74 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_73 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 246, 256)     238592      input_74[0][0]                   
__________________________________________________________________________________________________
dropout_73 (Dropout)            (None, 162)          0           input_73[0][0]                   
__________________________________________________________________________________________________
dropout_74 (Dropout)            (None, 246, 256)     0           embedding_37[0][0]               
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 256)          41728       dropout_73[0][0]                 
__________________________________________________________________________________________________
lstm_37 (LSTM)                  (None, 256)          525312      dropout_74[0][0]                 
__________________________________________________________________________________________________
add_37 (Add)                    (None, 256)          0           dense_109[0][0]                  
                                                                 lstm_37[0][0]                    
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 256)          65792       add_37[0][0]                     
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 932)          239524      dense_110[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.57387, saving model to model-ep001-loss4.161-val_loss3.574.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.57387 to 3.10487, saving model to model-ep002-loss2.582-val_loss3.105.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.10487 to 2.87030, saving model to model-ep003-loss2.104-val_loss2.870.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.87030 to 2.86842, saving model to model-ep004-loss1.848-val_loss2.868.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.86842 to 2.81042, saving model to model-ep005-loss1.670-val_loss2.810.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.81042
Epoch 7/10

Epoch 00007: val_loss improved from 2.81042 to 2.79153, saving model to model-ep007-loss1.403-val_loss2.792.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.79153
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.79153
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.79153
model-ep007-loss1.403-val_loss2.792.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.593121
BLEU-2: 0.440271
BLEU-3: 0.385444
BLEU-4: 0.286006
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_76 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_75 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 246, 256)     238592      input_76[0][0]                   
__________________________________________________________________________________________________
dropout_75 (Dropout)            (None, 162)          0           input_75[0][0]                   
__________________________________________________________________________________________________
dropout_76 (Dropout)            (None, 246, 256)     0           embedding_38[0][0]               
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 256)          41728       dropout_75[0][0]                 
__________________________________________________________________________________________________
lstm_38 (LSTM)                  (None, 256)          525312      dropout_76[0][0]                 
__________________________________________________________________________________________________
add_38 (Add)                    (None, 256)          0           dense_112[0][0]                  
                                                                 lstm_38[0][0]                    
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 256)          65792       add_38[0][0]                     
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 932)          239524      dense_113[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.16396, saving model to model-ep001-loss4.216-val_loss3.164.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.16396 to 2.58036, saving model to model-ep002-loss2.605-val_loss2.580.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.58036 to 2.36116, saving model to model-ep003-loss2.123-val_loss2.361.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.36116 to 2.33056, saving model to model-ep004-loss1.875-val_loss2.331.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.33056 to 2.30847, saving model to model-ep005-loss1.698-val_loss2.308.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.30847
Epoch 7/10

Epoch 00007: val_loss improved from 2.30847 to 2.27062, saving model to model-ep007-loss1.436-val_loss2.271.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.27062
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.27062
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.27062
model-ep007-loss1.436-val_loss2.271.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.594333
BLEU-2: 0.455360
BLEU-3: 0.404468
BLEU-4: 0.309935
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_78 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_77 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_39 (Embedding)        (None, 246, 256)     238592      input_78[0][0]                   
__________________________________________________________________________________________________
dropout_77 (Dropout)            (None, 162)          0           input_77[0][0]                   
__________________________________________________________________________________________________
dropout_78 (Dropout)            (None, 246, 256)     0           embedding_39[0][0]               
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 256)          41728       dropout_77[0][0]                 
__________________________________________________________________________________________________
lstm_39 (LSTM)                  (None, 256)          525312      dropout_78[0][0]                 
__________________________________________________________________________________________________
add_39 (Add)                    (None, 256)          0           dense_115[0][0]                  
                                                                 lstm_39[0][0]                    
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 256)          65792       add_39[0][0]                     
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 932)          239524      dense_116[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.26642, saving model to model-ep001-loss4.149-val_loss3.266.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.26642 to 2.77528, saving model to model-ep002-loss2.602-val_loss2.775.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.77528 to 2.61845, saving model to model-ep003-loss2.141-val_loss2.618.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.61845 to 2.54803, saving model to model-ep004-loss1.887-val_loss2.548.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.54803
Epoch 6/10

Epoch 00006: val_loss improved from 2.54803 to 2.50497, saving model to model-ep006-loss1.551-val_loss2.505.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.50497
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.50497
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.50497
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.50497
model-ep006-loss1.551-val_loss2.505.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.584378
BLEU-2: 0.449610
BLEU-3: 0.400480
BLEU-4: 0.308040
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_80 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_79 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_40 (Embedding)        (None, 246, 256)     238592      input_80[0][0]                   
__________________________________________________________________________________________________
dropout_79 (Dropout)            (None, 162)          0           input_79[0][0]                   
__________________________________________________________________________________________________
dropout_80 (Dropout)            (None, 246, 256)     0           embedding_40[0][0]               
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 256)          41728       dropout_79[0][0]                 
__________________________________________________________________________________________________
lstm_40 (LSTM)                  (None, 256)          525312      dropout_80[0][0]                 
__________________________________________________________________________________________________
add_40 (Add)                    (None, 256)          0           dense_118[0][0]                  
                                                                 lstm_40[0][0]                    
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 256)          65792       add_40[0][0]                     
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 932)          239524      dense_119[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.98402, saving model to model-ep001-loss4.188-val_loss2.984.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.98402 to 2.40179, saving model to model-ep002-loss2.548-val_loss2.402.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.40179 to 2.16901, saving model to model-ep003-loss2.075-val_loss2.169.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.16901 to 2.10916, saving model to model-ep004-loss1.837-val_loss2.109.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.10916 to 2.09675, saving model to model-ep005-loss1.660-val_loss2.097.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.09675
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.09675
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.09675
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.09675
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.09675
model-ep005-loss1.660-val_loss2.097.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.592324
BLEU-2: 0.445000
BLEU-3: 0.392304
BLEU-4: 0.294329
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_82 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_81 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_41 (Embedding)        (None, 246, 256)     238592      input_82[0][0]                   
__________________________________________________________________________________________________
dropout_81 (Dropout)            (None, 162)          0           input_81[0][0]                   
__________________________________________________________________________________________________
dropout_82 (Dropout)            (None, 246, 256)     0           embedding_41[0][0]               
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 256)          41728       dropout_81[0][0]                 
__________________________________________________________________________________________________
lstm_41 (LSTM)                  (None, 256)          525312      dropout_82[0][0]                 
__________________________________________________________________________________________________
add_41 (Add)                    (None, 256)          0           dense_121[0][0]                  
                                                                 lstm_41[0][0]                    
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 256)          65792       add_41[0][0]                     
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 932)          239524      dense_122[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.95622, saving model to model-ep001-loss4.145-val_loss2.956.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.95622 to 2.32038, saving model to model-ep002-loss2.586-val_loss2.320.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.32038 to 2.14188, saving model to model-ep003-loss2.125-val_loss2.142.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.14188 to 2.06426, saving model to model-ep004-loss1.883-val_loss2.064.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.06426 to 2.00233, saving model to model-ep005-loss1.705-val_loss2.002.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.00233 to 1.98082, saving model to model-ep006-loss1.561-val_loss1.981.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.98082
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.98082
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.98082
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.98082
model-ep006-loss1.561-val_loss1.981.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.598724
BLEU-2: 0.450982
BLEU-3: 0.393478
BLEU-4: 0.293049
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_84 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_83 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_42 (Embedding)        (None, 246, 256)     238592      input_84[0][0]                   
__________________________________________________________________________________________________
dropout_83 (Dropout)            (None, 162)          0           input_83[0][0]                   
__________________________________________________________________________________________________
dropout_84 (Dropout)            (None, 246, 256)     0           embedding_42[0][0]               
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 256)          41728       dropout_83[0][0]                 
__________________________________________________________________________________________________
lstm_42 (LSTM)                  (None, 256)          525312      dropout_84[0][0]                 
__________________________________________________________________________________________________
add_42 (Add)                    (None, 256)          0           dense_124[0][0]                  
                                                                 lstm_42[0][0]                    
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 256)          65792       add_42[0][0]                     
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 932)          239524      dense_125[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.22963, saving model to model-ep001-loss4.164-val_loss3.230.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.22963 to 2.60432, saving model to model-ep002-loss2.545-val_loss2.604.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.60432 to 2.40719, saving model to model-ep003-loss2.078-val_loss2.407.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.40719 to 2.28694, saving model to model-ep004-loss1.823-val_loss2.287.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.28694
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.28694
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.28694
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.28694
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.28694
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.28694
model-ep004-loss1.823-val_loss2.287.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.586794
BLEU-2: 0.444397
BLEU-3: 0.390558
BLEU-4: 0.294679
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_86 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_85 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_43 (Embedding)        (None, 246, 256)     238592      input_86[0][0]                   
__________________________________________________________________________________________________
dropout_85 (Dropout)            (None, 162)          0           input_85[0][0]                   
__________________________________________________________________________________________________
dropout_86 (Dropout)            (None, 246, 256)     0           embedding_43[0][0]               
__________________________________________________________________________________________________
dense_127 (Dense)               (None, 256)          41728       dropout_85[0][0]                 
__________________________________________________________________________________________________
lstm_43 (LSTM)                  (None, 256)          525312      dropout_86[0][0]                 
__________________________________________________________________________________________________
add_43 (Add)                    (None, 256)          0           dense_127[0][0]                  
                                                                 lstm_43[0][0]                    
__________________________________________________________________________________________________
dense_128 (Dense)               (None, 256)          65792       add_43[0][0]                     
__________________________________________________________________________________________________
dense_129 (Dense)               (None, 932)          239524      dense_128[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.69075, saving model to model-ep001-loss4.102-val_loss2.691.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.69075 to 2.11932, saving model to model-ep002-loss2.527-val_loss2.119.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.11932 to 1.90864, saving model to model-ep003-loss2.072-val_loss1.909.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.90864 to 1.87501, saving model to model-ep004-loss1.823-val_loss1.875.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.87501 to 1.84318, saving model to model-ep005-loss1.649-val_loss1.843.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.84318 to 1.83092, saving model to model-ep006-loss1.498-val_loss1.831.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.83092
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.83092
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.83092
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.83092
model-ep006-loss1.498-val_loss1.831.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.584178
BLEU-2: 0.447702
BLEU-3: 0.398179
BLEU-4: 0.305485
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_88 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_87 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_44 (Embedding)        (None, 246, 256)     238592      input_88[0][0]                   
__________________________________________________________________________________________________
dropout_87 (Dropout)            (None, 162)          0           input_87[0][0]                   
__________________________________________________________________________________________________
dropout_88 (Dropout)            (None, 246, 256)     0           embedding_44[0][0]               
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 256)          41728       dropout_87[0][0]                 
__________________________________________________________________________________________________
lstm_44 (LSTM)                  (None, 256)          525312      dropout_88[0][0]                 
__________________________________________________________________________________________________
add_44 (Add)                    (None, 256)          0           dense_130[0][0]                  
                                                                 lstm_44[0][0]                    
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 256)          65792       add_44[0][0]                     
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 932)          239524      dense_131[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 4.18184, saving model to model-ep001-loss4.187-val_loss4.182.h5
Epoch 2/10

Epoch 00002: val_loss improved from 4.18184 to 3.80234, saving model to model-ep002-loss2.537-val_loss3.802.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.80234 to 3.69046, saving model to model-ep003-loss2.077-val_loss3.690.h5
Epoch 4/10

Epoch 00004: val_loss improved from 3.69046 to 3.61649, saving model to model-ep004-loss1.825-val_loss3.616.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 3.61649
Epoch 6/10

Epoch 00006: val_loss improved from 3.61649 to 3.59146, saving model to model-ep006-loss1.508-val_loss3.591.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 3.59146
Epoch 8/10

Epoch 00008: val_loss did not improve from 3.59146
Epoch 9/10

Epoch 00009: val_loss did not improve from 3.59146
Epoch 10/10

Epoch 00010: val_loss did not improve from 3.59146
model-ep006-loss1.508-val_loss3.591.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.589856
BLEU-2: 0.451605
BLEU-3: 0.402273
BLEU-4: 0.307647
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_90 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_89 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_45 (Embedding)        (None, 246, 256)     238592      input_90[0][0]                   
__________________________________________________________________________________________________
dropout_89 (Dropout)            (None, 162)          0           input_89[0][0]                   
__________________________________________________________________________________________________
dropout_90 (Dropout)            (None, 246, 256)     0           embedding_45[0][0]               
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 256)          41728       dropout_89[0][0]                 
__________________________________________________________________________________________________
lstm_45 (LSTM)                  (None, 256)          525312      dropout_90[0][0]                 
__________________________________________________________________________________________________
add_45 (Add)                    (None, 256)          0           dense_133[0][0]                  
                                                                 lstm_45[0][0]                    
__________________________________________________________________________________________________
dense_134 (Dense)               (None, 256)          65792       add_45[0][0]                     
__________________________________________________________________________________________________
dense_135 (Dense)               (None, 932)          239524      dense_134[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.99023, saving model to model-ep001-loss4.196-val_loss2.990.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.99023 to 2.37141, saving model to model-ep002-loss2.596-val_loss2.371.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.37141 to 2.15445, saving model to model-ep003-loss2.134-val_loss2.154.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.15445 to 1.98678, saving model to model-ep004-loss1.890-val_loss1.987.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.98678 to 1.87541, saving model to model-ep005-loss1.715-val_loss1.875.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.87541 to 1.77794, saving model to model-ep006-loss1.575-val_loss1.778.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.77794
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.77794
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.77794
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.77794
model-ep006-loss1.575-val_loss1.778.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.538558
BLEU-2: 0.401155
BLEU-3: 0.351097
BLEU-4: 0.261840
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_92 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_91 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_46 (Embedding)        (None, 246, 256)     238592      input_92[0][0]                   
__________________________________________________________________________________________________
dropout_91 (Dropout)            (None, 162)          0           input_91[0][0]                   
__________________________________________________________________________________________________
dropout_92 (Dropout)            (None, 246, 256)     0           embedding_46[0][0]               
__________________________________________________________________________________________________
dense_136 (Dense)               (None, 256)          41728       dropout_91[0][0]                 
__________________________________________________________________________________________________
lstm_46 (LSTM)                  (None, 256)          525312      dropout_92[0][0]                 
__________________________________________________________________________________________________
add_46 (Add)                    (None, 256)          0           dense_136[0][0]                  
                                                                 lstm_46[0][0]                    
__________________________________________________________________________________________________
dense_137 (Dense)               (None, 256)          65792       add_46[0][0]                     
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 932)          239524      dense_137[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.70401, saving model to model-ep001-loss4.081-val_loss3.704.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.70401 to 3.12557, saving model to model-ep002-loss2.482-val_loss3.126.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.12557 to 2.89898, saving model to model-ep003-loss2.043-val_loss2.899.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.89898 to 2.89823, saving model to model-ep004-loss1.794-val_loss2.898.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.89823 to 2.84020, saving model to model-ep005-loss1.617-val_loss2.840.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.84020 to 2.80738, saving model to model-ep006-loss1.465-val_loss2.807.h5
Epoch 7/10

Epoch 00007: val_loss improved from 2.80738 to 2.80522, saving model to model-ep007-loss1.333-val_loss2.805.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.80522
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.80522
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.80522
model-ep007-loss1.333-val_loss2.805.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.577128
BLEU-2: 0.438374
BLEU-3: 0.387672
BLEU-4: 0.295064
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_94 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_93 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_47 (Embedding)        (None, 246, 256)     238592      input_94[0][0]                   
__________________________________________________________________________________________________
dropout_93 (Dropout)            (None, 162)          0           input_93[0][0]                   
__________________________________________________________________________________________________
dropout_94 (Dropout)            (None, 246, 256)     0           embedding_47[0][0]               
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 256)          41728       dropout_93[0][0]                 
__________________________________________________________________________________________________
lstm_47 (LSTM)                  (None, 256)          525312      dropout_94[0][0]                 
__________________________________________________________________________________________________
add_47 (Add)                    (None, 256)          0           dense_139[0][0]                  
                                                                 lstm_47[0][0]                    
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 256)          65792       add_47[0][0]                     
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 932)          239524      dense_140[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.70170, saving model to model-ep001-loss4.110-val_loss3.702.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.70170 to 3.18321, saving model to model-ep002-loss2.519-val_loss3.183.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.18321 to 3.06371, saving model to model-ep003-loss2.058-val_loss3.064.h5
Epoch 4/10

Epoch 00004: val_loss improved from 3.06371 to 2.98202, saving model to model-ep004-loss1.816-val_loss2.982.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.98202
Epoch 6/10

Epoch 00006: val_loss improved from 2.98202 to 2.92886, saving model to model-ep006-loss1.496-val_loss2.929.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.92886
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.92886
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.92886
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.92886
model-ep006-loss1.496-val_loss2.929.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.593278
BLEU-2: 0.451997
BLEU-3: 0.401272
BLEU-4: 0.306691
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_96 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_95 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_48 (Embedding)        (None, 246, 256)     238592      input_96[0][0]                   
__________________________________________________________________________________________________
dropout_95 (Dropout)            (None, 162)          0           input_95[0][0]                   
__________________________________________________________________________________________________
dropout_96 (Dropout)            (None, 246, 256)     0           embedding_48[0][0]               
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 256)          41728       dropout_95[0][0]                 
__________________________________________________________________________________________________
lstm_48 (LSTM)                  (None, 256)          525312      dropout_96[0][0]                 
__________________________________________________________________________________________________
add_48 (Add)                    (None, 256)          0           dense_142[0][0]                  
                                                                 lstm_48[0][0]                    
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 256)          65792       add_48[0][0]                     
__________________________________________________________________________________________________
dense_144 (Dense)               (None, 932)          239524      dense_143[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.24165, saving model to model-ep001-loss4.116-val_loss2.242.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.24165 to 1.63784, saving model to model-ep002-loss2.487-val_loss1.638.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.63784 to 1.48678, saving model to model-ep003-loss2.044-val_loss1.487.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.48678 to 1.47093, saving model to model-ep004-loss1.790-val_loss1.471.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.47093 to 1.35541, saving model to model-ep005-loss1.605-val_loss1.355.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.35541
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.35541
Epoch 8/10

Epoch 00008: val_loss improved from 1.35541 to 1.35127, saving model to model-ep008-loss1.188-val_loss1.351.h5
Epoch 9/10

Epoch 00009: val_loss improved from 1.35127 to 1.31843, saving model to model-ep009-loss1.078-val_loss1.318.h5
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.31843
model-ep009-loss1.078-val_loss1.318.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.546100
BLEU-2: 0.390653
BLEU-3: 0.335511
BLEU-4: 0.239591
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_98 (InputLayer)           (None, 246)          0                                            
__________________________________________________________________________________________________
input_97 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_49 (Embedding)        (None, 246, 256)     238592      input_98[0][0]                   
__________________________________________________________________________________________________
dropout_97 (Dropout)            (None, 162)          0           input_97[0][0]                   
__________________________________________________________________________________________________
dropout_98 (Dropout)            (None, 246, 256)     0           embedding_49[0][0]               
__________________________________________________________________________________________________
dense_145 (Dense)               (None, 256)          41728       dropout_97[0][0]                 
__________________________________________________________________________________________________
lstm_49 (LSTM)                  (None, 256)          525312      dropout_98[0][0]                 
__________________________________________________________________________________________________
add_49 (Add)                    (None, 256)          0           dense_145[0][0]                  
                                                                 lstm_49[0][0]                    
__________________________________________________________________________________________________
dense_146 (Dense)               (None, 256)          65792       add_49[0][0]                     
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 932)          239524      dense_146[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.62886, saving model to model-ep001-loss4.197-val_loss3.629.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.62886 to 3.01851, saving model to model-ep002-loss2.576-val_loss3.019.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.01851 to 2.86957, saving model to model-ep003-loss2.097-val_loss2.870.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.86957 to 2.80528, saving model to model-ep004-loss1.849-val_loss2.805.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.80528
Epoch 6/10

Epoch 00006: val_loss improved from 2.80528 to 2.69690, saving model to model-ep006-loss1.518-val_loss2.697.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.69690
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.69690
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.69690
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.69690
model-ep006-loss1.518-val_loss2.697.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.573357
BLEU-2: 0.435128
BLEU-3: 0.382824
BLEU-4: 0.288381
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_100 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_99 (InputLayer)           (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_50 (Embedding)        (None, 246, 256)     238592      input_100[0][0]                  
__________________________________________________________________________________________________
dropout_99 (Dropout)            (None, 162)          0           input_99[0][0]                   
__________________________________________________________________________________________________
dropout_100 (Dropout)           (None, 246, 256)     0           embedding_50[0][0]               
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 256)          41728       dropout_99[0][0]                 
__________________________________________________________________________________________________
lstm_50 (LSTM)                  (None, 256)          525312      dropout_100[0][0]                
__________________________________________________________________________________________________
add_50 (Add)                    (None, 256)          0           dense_148[0][0]                  
                                                                 lstm_50[0][0]                    
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 256)          65792       add_50[0][0]                     
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 932)          239524      dense_149[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.62311, saving model to model-ep001-loss4.179-val_loss3.623.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.62311 to 3.13562, saving model to model-ep002-loss2.541-val_loss3.136.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.13562 to 2.93188, saving model to model-ep003-loss2.085-val_loss2.932.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.93188 to 2.85709, saving model to model-ep004-loss1.841-val_loss2.857.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.85709
Epoch 6/10

Epoch 00006: val_loss improved from 2.85709 to 2.84454, saving model to model-ep006-loss1.524-val_loss2.845.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.84454
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.84454
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.84454
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.84454
model-ep006-loss1.524-val_loss2.845.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.584148
BLEU-2: 0.442385
BLEU-3: 0.392275
BLEU-4: 0.298474
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_102 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_101 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_51 (Embedding)        (None, 246, 256)     238592      input_102[0][0]                  
__________________________________________________________________________________________________
dropout_101 (Dropout)           (None, 162)          0           input_101[0][0]                  
__________________________________________________________________________________________________
dropout_102 (Dropout)           (None, 246, 256)     0           embedding_51[0][0]               
__________________________________________________________________________________________________
dense_151 (Dense)               (None, 256)          41728       dropout_101[0][0]                
__________________________________________________________________________________________________
lstm_51 (LSTM)                  (None, 256)          525312      dropout_102[0][0]                
__________________________________________________________________________________________________
add_51 (Add)                    (None, 256)          0           dense_151[0][0]                  
                                                                 lstm_51[0][0]                    
__________________________________________________________________________________________________
dense_152 (Dense)               (None, 256)          65792       add_51[0][0]                     
__________________________________________________________________________________________________
dense_153 (Dense)               (None, 932)          239524      dense_152[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.64021, saving model to model-ep001-loss4.163-val_loss2.640.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.64021 to 2.11423, saving model to model-ep002-loss2.555-val_loss2.114.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.11423 to 1.90799, saving model to model-ep003-loss2.089-val_loss1.908.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.90799 to 1.88740, saving model to model-ep004-loss1.833-val_loss1.887.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.88740 to 1.83132, saving model to model-ep005-loss1.658-val_loss1.831.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.83132
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.83132
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.83132
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.83132
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.83132
model-ep005-loss1.658-val_loss1.831.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.580849
BLEU-2: 0.438685
BLEU-3: 0.387401
BLEU-4: 0.292655
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_104 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_103 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_52 (Embedding)        (None, 246, 256)     238592      input_104[0][0]                  
__________________________________________________________________________________________________
dropout_103 (Dropout)           (None, 162)          0           input_103[0][0]                  
__________________________________________________________________________________________________
dropout_104 (Dropout)           (None, 246, 256)     0           embedding_52[0][0]               
__________________________________________________________________________________________________
dense_154 (Dense)               (None, 256)          41728       dropout_103[0][0]                
__________________________________________________________________________________________________
lstm_52 (LSTM)                  (None, 256)          525312      dropout_104[0][0]                
__________________________________________________________________________________________________
add_52 (Add)                    (None, 256)          0           dense_154[0][0]                  
                                                                 lstm_52[0][0]                    
__________________________________________________________________________________________________
dense_155 (Dense)               (None, 256)          65792       add_52[0][0]                     
__________________________________________________________________________________________________
dense_156 (Dense)               (None, 932)          239524      dense_155[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.43851, saving model to model-ep001-loss4.184-val_loss2.439.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.43851 to 1.83392, saving model to model-ep002-loss2.569-val_loss1.834.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.83392 to 1.53208, saving model to model-ep003-loss2.080-val_loss1.532.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.53208 to 1.43996, saving model to model-ep004-loss1.829-val_loss1.440.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.43996 to 1.37621, saving model to model-ep005-loss1.643-val_loss1.376.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.37621 to 1.35632, saving model to model-ep006-loss1.491-val_loss1.356.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.35632 to 1.33387, saving model to model-ep007-loss1.362-val_loss1.334.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.33387
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.33387
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.33387
model-ep007-loss1.362-val_loss1.334.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.578856
BLEU-2: 0.430574
BLEU-3: 0.373963
BLEU-4: 0.277951
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_106 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_105 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_53 (Embedding)        (None, 246, 256)     238592      input_106[0][0]                  
__________________________________________________________________________________________________
dropout_105 (Dropout)           (None, 162)          0           input_105[0][0]                  
__________________________________________________________________________________________________
dropout_106 (Dropout)           (None, 246, 256)     0           embedding_53[0][0]               
__________________________________________________________________________________________________
dense_157 (Dense)               (None, 256)          41728       dropout_105[0][0]                
__________________________________________________________________________________________________
lstm_53 (LSTM)                  (None, 256)          525312      dropout_106[0][0]                
__________________________________________________________________________________________________
add_53 (Add)                    (None, 256)          0           dense_157[0][0]                  
                                                                 lstm_53[0][0]                    
__________________________________________________________________________________________________
dense_158 (Dense)               (None, 256)          65792       add_53[0][0]                     
__________________________________________________________________________________________________
dense_159 (Dense)               (None, 932)          239524      dense_158[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.63721, saving model to model-ep001-loss4.084-val_loss2.637.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.63721 to 2.06756, saving model to model-ep002-loss2.482-val_loss2.068.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.06756 to 1.95163, saving model to model-ep003-loss2.035-val_loss1.952.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.95163 to 1.83597, saving model to model-ep004-loss1.792-val_loss1.836.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 1.83597
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.83597
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.83597
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.83597
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.83597
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.83597
model-ep004-loss1.792-val_loss1.836.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.585395
BLEU-2: 0.445045
BLEU-3: 0.395155
BLEU-4: 0.297577
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_108 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_107 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_54 (Embedding)        (None, 246, 256)     238592      input_108[0][0]                  
__________________________________________________________________________________________________
dropout_107 (Dropout)           (None, 162)          0           input_107[0][0]                  
__________________________________________________________________________________________________
dropout_108 (Dropout)           (None, 246, 256)     0           embedding_54[0][0]               
__________________________________________________________________________________________________
dense_160 (Dense)               (None, 256)          41728       dropout_107[0][0]                
__________________________________________________________________________________________________
lstm_54 (LSTM)                  (None, 256)          525312      dropout_108[0][0]                
__________________________________________________________________________________________________
add_54 (Add)                    (None, 256)          0           dense_160[0][0]                  
                                                                 lstm_54[0][0]                    
__________________________________________________________________________________________________
dense_161 (Dense)               (None, 256)          65792       add_54[0][0]                     
__________________________________________________________________________________________________
dense_162 (Dense)               (None, 932)          239524      dense_161[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.54698, saving model to model-ep001-loss4.196-val_loss3.547.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.54698 to 2.95549, saving model to model-ep002-loss2.583-val_loss2.955.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.95549 to 2.81621, saving model to model-ep003-loss2.103-val_loss2.816.h5
Epoch 4/10

Epoch 00004: val_loss did not improve from 2.81621
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.81621
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.81621
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.81621
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.81621
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.81621
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.81621
model-ep003-loss2.103-val_loss2.816.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.561302
BLEU-2: 0.432578
BLEU-3: 0.384579
BLEU-4: 0.295629
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_110 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_109 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_55 (Embedding)        (None, 246, 256)     238592      input_110[0][0]                  
__________________________________________________________________________________________________
dropout_109 (Dropout)           (None, 162)          0           input_109[0][0]                  
__________________________________________________________________________________________________
dropout_110 (Dropout)           (None, 246, 256)     0           embedding_55[0][0]               
__________________________________________________________________________________________________
dense_163 (Dense)               (None, 256)          41728       dropout_109[0][0]                
__________________________________________________________________________________________________
lstm_55 (LSTM)                  (None, 256)          525312      dropout_110[0][0]                
__________________________________________________________________________________________________
add_55 (Add)                    (None, 256)          0           dense_163[0][0]                  
                                                                 lstm_55[0][0]                    
__________________________________________________________________________________________________
dense_164 (Dense)               (None, 256)          65792       add_55[0][0]                     
__________________________________________________________________________________________________
dense_165 (Dense)               (None, 932)          239524      dense_164[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.23188, saving model to model-ep001-loss4.217-val_loss3.232.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.23188 to 2.40148, saving model to model-ep002-loss2.602-val_loss2.401.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.40148 to 2.11013, saving model to model-ep003-loss2.124-val_loss2.110.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.11013 to 1.88804, saving model to model-ep004-loss1.875-val_loss1.888.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.88804 to 1.87403, saving model to model-ep005-loss1.695-val_loss1.874.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.87403 to 1.74052, saving model to model-ep006-loss1.561-val_loss1.741.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.74052 to 1.69577, saving model to model-ep007-loss1.430-val_loss1.696.h5
Epoch 8/10

Epoch 00008: val_loss improved from 1.69577 to 1.68162, saving model to model-ep008-loss1.324-val_loss1.682.h5
Epoch 9/10

Epoch 00009: val_loss improved from 1.68162 to 1.60629, saving model to model-ep009-loss1.225-val_loss1.606.h5
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.60629
model-ep009-loss1.225-val_loss1.606.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.599225
BLEU-2: 0.447781
BLEU-3: 0.392345
BLEU-4: 0.290392
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_112 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_111 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_56 (Embedding)        (None, 246, 256)     238592      input_112[0][0]                  
__________________________________________________________________________________________________
dropout_111 (Dropout)           (None, 162)          0           input_111[0][0]                  
__________________________________________________________________________________________________
dropout_112 (Dropout)           (None, 246, 256)     0           embedding_56[0][0]               
__________________________________________________________________________________________________
dense_166 (Dense)               (None, 256)          41728       dropout_111[0][0]                
__________________________________________________________________________________________________
lstm_56 (LSTM)                  (None, 256)          525312      dropout_112[0][0]                
__________________________________________________________________________________________________
add_56 (Add)                    (None, 256)          0           dense_166[0][0]                  
                                                                 lstm_56[0][0]                    
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 256)          65792       add_56[0][0]                     
__________________________________________________________________________________________________
dense_168 (Dense)               (None, 932)          239524      dense_167[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.45185, saving model to model-ep001-loss4.220-val_loss2.452.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.45185 to 1.65081, saving model to model-ep002-loss2.627-val_loss1.651.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.65081 to 1.45882, saving model to model-ep003-loss2.137-val_loss1.459.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.45882 to 1.35071, saving model to model-ep004-loss1.876-val_loss1.351.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.35071 to 1.32338, saving model to model-ep005-loss1.700-val_loss1.323.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.32338 to 1.28195, saving model to model-ep006-loss1.554-val_loss1.282.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.28195
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.28195
Epoch 9/10

Epoch 00009: val_loss improved from 1.28195 to 1.24062, saving model to model-ep009-loss1.223-val_loss1.241.h5
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.24062
model-ep009-loss1.223-val_loss1.241.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.449227
BLEU-2: 0.331241
BLEU-3: 0.296943
BLEU-4: 0.207744
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_114 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_113 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_57 (Embedding)        (None, 246, 256)     238592      input_114[0][0]                  
__________________________________________________________________________________________________
dropout_113 (Dropout)           (None, 162)          0           input_113[0][0]                  
__________________________________________________________________________________________________
dropout_114 (Dropout)           (None, 246, 256)     0           embedding_57[0][0]               
__________________________________________________________________________________________________
dense_169 (Dense)               (None, 256)          41728       dropout_113[0][0]                
__________________________________________________________________________________________________
lstm_57 (LSTM)                  (None, 256)          525312      dropout_114[0][0]                
__________________________________________________________________________________________________
add_57 (Add)                    (None, 256)          0           dense_169[0][0]                  
                                                                 lstm_57[0][0]                    
__________________________________________________________________________________________________
dense_170 (Dense)               (None, 256)          65792       add_57[0][0]                     
__________________________________________________________________________________________________
dense_171 (Dense)               (None, 932)          239524      dense_170[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.56572, saving model to model-ep001-loss4.144-val_loss3.566.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.56572 to 2.85459, saving model to model-ep002-loss2.544-val_loss2.855.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.85459 to 2.82593, saving model to model-ep003-loss2.081-val_loss2.826.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.82593 to 2.77136, saving model to model-ep004-loss1.833-val_loss2.771.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.77136 to 2.59629, saving model to model-ep005-loss1.663-val_loss2.596.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.59629
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.59629
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.59629
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.59629
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.59629
model-ep005-loss1.663-val_loss2.596.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.572095
BLEU-2: 0.436778
BLEU-3: 0.390014
BLEU-4: 0.299393
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_116 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_115 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_58 (Embedding)        (None, 246, 256)     238592      input_116[0][0]                  
__________________________________________________________________________________________________
dropout_115 (Dropout)           (None, 162)          0           input_115[0][0]                  
__________________________________________________________________________________________________
dropout_116 (Dropout)           (None, 246, 256)     0           embedding_58[0][0]               
__________________________________________________________________________________________________
dense_172 (Dense)               (None, 256)          41728       dropout_115[0][0]                
__________________________________________________________________________________________________
lstm_58 (LSTM)                  (None, 256)          525312      dropout_116[0][0]                
__________________________________________________________________________________________________
add_58 (Add)                    (None, 256)          0           dense_172[0][0]                  
                                                                 lstm_58[0][0]                    
__________________________________________________________________________________________________
dense_173 (Dense)               (None, 256)          65792       add_58[0][0]                     
__________________________________________________________________________________________________
dense_174 (Dense)               (None, 932)          239524      dense_173[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.85880, saving model to model-ep001-loss4.103-val_loss2.859.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.85880 to 2.49560, saving model to model-ep002-loss2.549-val_loss2.496.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.49560 to 2.27613, saving model to model-ep003-loss2.084-val_loss2.276.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.27613 to 2.17159, saving model to model-ep004-loss1.829-val_loss2.172.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.17159 to 2.09690, saving model to model-ep005-loss1.647-val_loss2.097.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.09690
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.09690
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.09690
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.09690
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.09690
model-ep005-loss1.647-val_loss2.097.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.593539
BLEU-2: 0.451921
BLEU-3: 0.403072
BLEU-4: 0.307834
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_118 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_117 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_59 (Embedding)        (None, 246, 256)     238592      input_118[0][0]                  
__________________________________________________________________________________________________
dropout_117 (Dropout)           (None, 162)          0           input_117[0][0]                  
__________________________________________________________________________________________________
dropout_118 (Dropout)           (None, 246, 256)     0           embedding_59[0][0]               
__________________________________________________________________________________________________
dense_175 (Dense)               (None, 256)          41728       dropout_117[0][0]                
__________________________________________________________________________________________________
lstm_59 (LSTM)                  (None, 256)          525312      dropout_118[0][0]                
__________________________________________________________________________________________________
add_59 (Add)                    (None, 256)          0           dense_175[0][0]                  
                                                                 lstm_59[0][0]                    
__________________________________________________________________________________________________
dense_176 (Dense)               (None, 256)          65792       add_59[0][0]                     
__________________________________________________________________________________________________
dense_177 (Dense)               (None, 932)          239524      dense_176[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.10625, saving model to model-ep001-loss4.066-val_loss3.106.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.10625 to 2.72896, saving model to model-ep002-loss2.524-val_loss2.729.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.72896 to 2.47124, saving model to model-ep003-loss2.094-val_loss2.471.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.47124 to 2.43245, saving model to model-ep004-loss1.861-val_loss2.432.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.43245
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.43245
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.43245
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.43245
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.43245
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.43245
model-ep004-loss1.861-val_loss2.432.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.574780
BLEU-2: 0.415267
BLEU-3: 0.358891
BLEU-4: 0.260087
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_120 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_119 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_60 (Embedding)        (None, 246, 256)     238592      input_120[0][0]                  
__________________________________________________________________________________________________
dropout_119 (Dropout)           (None, 162)          0           input_119[0][0]                  
__________________________________________________________________________________________________
dropout_120 (Dropout)           (None, 246, 256)     0           embedding_60[0][0]               
__________________________________________________________________________________________________
dense_178 (Dense)               (None, 256)          41728       dropout_119[0][0]                
__________________________________________________________________________________________________
lstm_60 (LSTM)                  (None, 256)          525312      dropout_120[0][0]                
__________________________________________________________________________________________________
add_60 (Add)                    (None, 256)          0           dense_178[0][0]                  
                                                                 lstm_60[0][0]                    
__________________________________________________________________________________________________
dense_179 (Dense)               (None, 256)          65792       add_60[0][0]                     
__________________________________________________________________________________________________
dense_180 (Dense)               (None, 932)          239524      dense_179[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.73561, saving model to model-ep001-loss4.130-val_loss2.736.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.73561 to 2.09060, saving model to model-ep002-loss2.534-val_loss2.091.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.09060 to 1.85783, saving model to model-ep003-loss2.073-val_loss1.858.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.85783 to 1.69478, saving model to model-ep004-loss1.822-val_loss1.695.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.69478 to 1.66660, saving model to model-ep005-loss1.644-val_loss1.667.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.66660 to 1.62478, saving model to model-ep006-loss1.491-val_loss1.625.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.62478 to 1.60713, saving model to model-ep007-loss1.359-val_loss1.607.h5
Epoch 8/10

Epoch 00008: val_loss improved from 1.60713 to 1.60100, saving model to model-ep008-loss1.243-val_loss1.601.h5
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.60100
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.60100
model-ep008-loss1.243-val_loss1.601.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.601788
BLEU-2: 0.447646
BLEU-3: 0.394278
BLEU-4: 0.294676
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_122 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_121 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_61 (Embedding)        (None, 246, 256)     238592      input_122[0][0]                  
__________________________________________________________________________________________________
dropout_121 (Dropout)           (None, 162)          0           input_121[0][0]                  
__________________________________________________________________________________________________
dropout_122 (Dropout)           (None, 246, 256)     0           embedding_61[0][0]               
__________________________________________________________________________________________________
dense_181 (Dense)               (None, 256)          41728       dropout_121[0][0]                
__________________________________________________________________________________________________
lstm_61 (LSTM)                  (None, 256)          525312      dropout_122[0][0]                
__________________________________________________________________________________________________
add_61 (Add)                    (None, 256)          0           dense_181[0][0]                  
                                                                 lstm_61[0][0]                    
__________________________________________________________________________________________________
dense_182 (Dense)               (None, 256)          65792       add_61[0][0]                     
__________________________________________________________________________________________________
dense_183 (Dense)               (None, 932)          239524      dense_182[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.25647, saving model to model-ep001-loss4.108-val_loss2.256.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.25647 to 1.60227, saving model to model-ep002-loss2.536-val_loss1.602.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.60227 to 1.51290, saving model to model-ep003-loss2.083-val_loss1.513.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.51290 to 1.46607, saving model to model-ep004-loss1.835-val_loss1.466.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.46607 to 1.44573, saving model to model-ep005-loss1.650-val_loss1.446.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.44573
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.44573
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.44573
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.44573
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.44573
model-ep005-loss1.650-val_loss1.446.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.549711
BLEU-2: 0.407893
BLEU-3: 0.350097
BLEU-4: 0.253592
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_124 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_123 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_62 (Embedding)        (None, 246, 256)     238592      input_124[0][0]                  
__________________________________________________________________________________________________
dropout_123 (Dropout)           (None, 162)          0           input_123[0][0]                  
__________________________________________________________________________________________________
dropout_124 (Dropout)           (None, 246, 256)     0           embedding_62[0][0]               
__________________________________________________________________________________________________
dense_184 (Dense)               (None, 256)          41728       dropout_123[0][0]                
__________________________________________________________________________________________________
lstm_62 (LSTM)                  (None, 256)          525312      dropout_124[0][0]                
__________________________________________________________________________________________________
add_62 (Add)                    (None, 256)          0           dense_184[0][0]                  
                                                                 lstm_62[0][0]                    
__________________________________________________________________________________________________
dense_185 (Dense)               (None, 256)          65792       add_62[0][0]                     
__________________________________________________________________________________________________
dense_186 (Dense)               (None, 932)          239524      dense_185[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.74379, saving model to model-ep001-loss4.117-val_loss2.744.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.74379 to 2.34120, saving model to model-ep002-loss2.489-val_loss2.341.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.34120 to 2.13135, saving model to model-ep003-loss2.039-val_loss2.131.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.13135 to 2.01463, saving model to model-ep004-loss1.798-val_loss2.015.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.01463 to 1.98170, saving model to model-ep005-loss1.617-val_loss1.982.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.98170
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.98170
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.98170
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.98170
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.98170
model-ep005-loss1.617-val_loss1.982.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.596132
BLEU-2: 0.454354
BLEU-3: 0.404222
BLEU-4: 0.309031
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_126 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_125 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_63 (Embedding)        (None, 246, 256)     238592      input_126[0][0]                  
__________________________________________________________________________________________________
dropout_125 (Dropout)           (None, 162)          0           input_125[0][0]                  
__________________________________________________________________________________________________
dropout_126 (Dropout)           (None, 246, 256)     0           embedding_63[0][0]               
__________________________________________________________________________________________________
dense_187 (Dense)               (None, 256)          41728       dropout_125[0][0]                
__________________________________________________________________________________________________
lstm_63 (LSTM)                  (None, 256)          525312      dropout_126[0][0]                
__________________________________________________________________________________________________
add_63 (Add)                    (None, 256)          0           dense_187[0][0]                  
                                                                 lstm_63[0][0]                    
__________________________________________________________________________________________________
dense_188 (Dense)               (None, 256)          65792       add_63[0][0]                     
__________________________________________________________________________________________________
dense_189 (Dense)               (None, 932)          239524      dense_188[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.97520, saving model to model-ep001-loss4.523-val_loss3.975.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.97520 to 3.12413, saving model to model-ep002-loss3.014-val_loss3.124.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.12413 to 2.83229, saving model to model-ep003-loss2.378-val_loss2.832.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.83229 to 2.62063, saving model to model-ep004-loss2.068-val_loss2.621.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.62063 to 2.58724, saving model to model-ep005-loss1.866-val_loss2.587.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.58724
Epoch 7/10

Epoch 00007: val_loss improved from 2.58724 to 2.52703, saving model to model-ep007-loss1.594-val_loss2.527.h5
Epoch 8/10

Epoch 00008: val_loss improved from 2.52703 to 2.49836, saving model to model-ep008-loss1.486-val_loss2.498.h5
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.49836
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.49836
model-ep008-loss1.486-val_loss2.498.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.582428
BLEU-2: 0.446795
BLEU-3: 0.396385
BLEU-4: 0.302583
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_128 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_127 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_64 (Embedding)        (None, 246, 256)     238592      input_128[0][0]                  
__________________________________________________________________________________________________
dropout_127 (Dropout)           (None, 162)          0           input_127[0][0]                  
__________________________________________________________________________________________________
dropout_128 (Dropout)           (None, 246, 256)     0           embedding_64[0][0]               
__________________________________________________________________________________________________
dense_190 (Dense)               (None, 256)          41728       dropout_127[0][0]                
__________________________________________________________________________________________________
lstm_64 (LSTM)                  (None, 256)          525312      dropout_128[0][0]                
__________________________________________________________________________________________________
add_64 (Add)                    (None, 256)          0           dense_190[0][0]                  
                                                                 lstm_64[0][0]                    
__________________________________________________________________________________________________
dense_191 (Dense)               (None, 256)          65792       add_64[0][0]                     
__________________________________________________________________________________________________
dense_192 (Dense)               (None, 932)          239524      dense_191[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 1.92285, saving model to model-ep001-loss4.164-val_loss1.923.h5
Epoch 2/10

Epoch 00002: val_loss improved from 1.92285 to 1.31044, saving model to model-ep002-loss2.544-val_loss1.310.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.31044 to 1.18995, saving model to model-ep003-loss2.081-val_loss1.190.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.18995 to 1.13070, saving model to model-ep004-loss1.830-val_loss1.131.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.13070 to 1.09301, saving model to model-ep005-loss1.655-val_loss1.093.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.09301 to 1.08707, saving model to model-ep006-loss1.504-val_loss1.087.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.08707 to 1.01984, saving model to model-ep007-loss1.384-val_loss1.020.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.01984
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.01984
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.01984
model-ep007-loss1.384-val_loss1.020.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.555154
BLEU-2: 0.418924
BLEU-3: 0.372374
BLEU-4: 0.283755
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_130 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_129 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_65 (Embedding)        (None, 246, 256)     238592      input_130[0][0]                  
__________________________________________________________________________________________________
dropout_129 (Dropout)           (None, 162)          0           input_129[0][0]                  
__________________________________________________________________________________________________
dropout_130 (Dropout)           (None, 246, 256)     0           embedding_65[0][0]               
__________________________________________________________________________________________________
dense_193 (Dense)               (None, 256)          41728       dropout_129[0][0]                
__________________________________________________________________________________________________
lstm_65 (LSTM)                  (None, 256)          525312      dropout_130[0][0]                
__________________________________________________________________________________________________
add_65 (Add)                    (None, 256)          0           dense_193[0][0]                  
                                                                 lstm_65[0][0]                    
__________________________________________________________________________________________________
dense_194 (Dense)               (None, 256)          65792       add_65[0][0]                     
__________________________________________________________________________________________________
dense_195 (Dense)               (None, 932)          239524      dense_194[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.01866, saving model to model-ep001-loss4.115-val_loss3.019.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.01866 to 2.57542, saving model to model-ep002-loss2.511-val_loss2.575.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.57542 to 2.34911, saving model to model-ep003-loss2.054-val_loss2.349.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.34911 to 2.32423, saving model to model-ep004-loss1.803-val_loss2.324.h5
Epoch 5/10

Epoch 00005: val_loss improved from 2.32423 to 2.19579, saving model to model-ep005-loss1.624-val_loss2.196.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.19579
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.19579
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.19579
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.19579
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.19579
model-ep005-loss1.624-val_loss2.196.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.568377
BLEU-2: 0.431624
BLEU-3: 0.383114
BLEU-4: 0.292194
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_132 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_131 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_66 (Embedding)        (None, 246, 256)     238592      input_132[0][0]                  
__________________________________________________________________________________________________
dropout_131 (Dropout)           (None, 162)          0           input_131[0][0]                  
__________________________________________________________________________________________________
dropout_132 (Dropout)           (None, 246, 256)     0           embedding_66[0][0]               
__________________________________________________________________________________________________
dense_196 (Dense)               (None, 256)          41728       dropout_131[0][0]                
__________________________________________________________________________________________________
lstm_66 (LSTM)                  (None, 256)          525312      dropout_132[0][0]                
__________________________________________________________________________________________________
add_66 (Add)                    (None, 256)          0           dense_196[0][0]                  
                                                                 lstm_66[0][0]                    
__________________________________________________________________________________________________
dense_197 (Dense)               (None, 256)          65792       add_66[0][0]                     
__________________________________________________________________________________________________
dense_198 (Dense)               (None, 932)          239524      dense_197[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.61697, saving model to model-ep001-loss4.205-val_loss2.617.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.61697 to 1.91169, saving model to model-ep002-loss2.584-val_loss1.912.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.91169 to 1.69519, saving model to model-ep003-loss2.086-val_loss1.695.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.69519 to 1.66117, saving model to model-ep004-loss1.830-val_loss1.661.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.66117 to 1.57123, saving model to model-ep005-loss1.657-val_loss1.571.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.57123
Epoch 7/10

Epoch 00007: val_loss improved from 1.57123 to 1.48376, saving model to model-ep007-loss1.380-val_loss1.484.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.48376
Epoch 9/10

Epoch 00009: val_loss improved from 1.48376 to 1.47699, saving model to model-ep009-loss1.161-val_loss1.477.h5
Epoch 10/10

Epoch 00010: val_loss improved from 1.47699 to 1.46260, saving model to model-ep010-loss1.060-val_loss1.463.h5
model-ep010-loss1.060-val_loss1.463.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.588644
BLEU-2: 0.451180
BLEU-3: 0.400692
BLEU-4: 0.306706
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_134 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_133 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_67 (Embedding)        (None, 246, 256)     238592      input_134[0][0]                  
__________________________________________________________________________________________________
dropout_133 (Dropout)           (None, 162)          0           input_133[0][0]                  
__________________________________________________________________________________________________
dropout_134 (Dropout)           (None, 246, 256)     0           embedding_67[0][0]               
__________________________________________________________________________________________________
dense_199 (Dense)               (None, 256)          41728       dropout_133[0][0]                
__________________________________________________________________________________________________
lstm_67 (LSTM)                  (None, 256)          525312      dropout_134[0][0]                
__________________________________________________________________________________________________
add_67 (Add)                    (None, 256)          0           dense_199[0][0]                  
                                                                 lstm_67[0][0]                    
__________________________________________________________________________________________________
dense_200 (Dense)               (None, 256)          65792       add_67[0][0]                     
__________________________________________________________________________________________________
dense_201 (Dense)               (None, 932)          239524      dense_200[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.40134, saving model to model-ep001-loss4.146-val_loss2.401.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.40134 to 1.88894, saving model to model-ep002-loss2.543-val_loss1.889.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.88894 to 1.81840, saving model to model-ep003-loss2.083-val_loss1.818.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.81840 to 1.81054, saving model to model-ep004-loss1.836-val_loss1.811.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.81054 to 1.76429, saving model to model-ep005-loss1.663-val_loss1.764.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 1.76429
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.76429
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.76429
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.76429
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.76429
model-ep005-loss1.663-val_loss1.764.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.593562
BLEU-2: 0.450180
BLEU-3: 0.398504
BLEU-4: 0.302011
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_136 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_135 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_68 (Embedding)        (None, 246, 256)     238592      input_136[0][0]                  
__________________________________________________________________________________________________
dropout_135 (Dropout)           (None, 162)          0           input_135[0][0]                  
__________________________________________________________________________________________________
dropout_136 (Dropout)           (None, 246, 256)     0           embedding_68[0][0]               
__________________________________________________________________________________________________
dense_202 (Dense)               (None, 256)          41728       dropout_135[0][0]                
__________________________________________________________________________________________________
lstm_68 (LSTM)                  (None, 256)          525312      dropout_136[0][0]                
__________________________________________________________________________________________________
add_68 (Add)                    (None, 256)          0           dense_202[0][0]                  
                                                                 lstm_68[0][0]                    
__________________________________________________________________________________________________
dense_203 (Dense)               (None, 256)          65792       add_68[0][0]                     
__________________________________________________________________________________________________
dense_204 (Dense)               (None, 932)          239524      dense_203[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.51479, saving model to model-ep001-loss4.077-val_loss3.515.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.51479 to 2.91135, saving model to model-ep002-loss2.520-val_loss2.911.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.91135 to 2.74644, saving model to model-ep003-loss2.065-val_loss2.746.h5
Epoch 4/10

Epoch 00004: val_loss improved from 2.74644 to 2.51867, saving model to model-ep004-loss1.812-val_loss2.519.h5
Epoch 5/10

Epoch 00005: val_loss did not improve from 2.51867
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.51867
Epoch 7/10

Epoch 00007: val_loss improved from 2.51867 to 2.50615, saving model to model-ep007-loss1.349-val_loss2.506.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.50615
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.50615
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.50615
model-ep007-loss1.349-val_loss2.506.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.594333
BLEU-2: 0.455426
BLEU-3: 0.406439
BLEU-4: 0.310994
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_138 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_137 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_69 (Embedding)        (None, 246, 256)     238592      input_138[0][0]                  
__________________________________________________________________________________________________
dropout_137 (Dropout)           (None, 162)          0           input_137[0][0]                  
__________________________________________________________________________________________________
dropout_138 (Dropout)           (None, 246, 256)     0           embedding_69[0][0]               
__________________________________________________________________________________________________
dense_205 (Dense)               (None, 256)          41728       dropout_137[0][0]                
__________________________________________________________________________________________________
lstm_69 (LSTM)                  (None, 256)          525312      dropout_138[0][0]                
__________________________________________________________________________________________________
add_69 (Add)                    (None, 256)          0           dense_205[0][0]                  
                                                                 lstm_69[0][0]                    
__________________________________________________________________________________________________
dense_206 (Dense)               (None, 256)          65792       add_69[0][0]                     
__________________________________________________________________________________________________
dense_207 (Dense)               (None, 932)          239524      dense_206[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.73825, saving model to model-ep001-loss4.131-val_loss2.738.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.73825 to 2.17047, saving model to model-ep002-loss2.535-val_loss2.170.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.17047 to 2.11296, saving model to model-ep003-loss2.068-val_loss2.113.h5
Epoch 4/10

Epoch 00004: val_loss did not improve from 2.11296
Epoch 5/10

Epoch 00005: val_loss improved from 2.11296 to 2.07627, saving model to model-ep005-loss1.648-val_loss2.076.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.07627
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.07627
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.07627
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.07627
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.07627
model-ep005-loss1.648-val_loss2.076.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.606043
BLEU-2: 0.461828
BLEU-3: 0.411220
BLEU-4: 0.312808
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_140 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_139 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_70 (Embedding)        (None, 246, 256)     238592      input_140[0][0]                  
__________________________________________________________________________________________________
dropout_139 (Dropout)           (None, 162)          0           input_139[0][0]                  
__________________________________________________________________________________________________
dropout_140 (Dropout)           (None, 246, 256)     0           embedding_70[0][0]               
__________________________________________________________________________________________________
dense_208 (Dense)               (None, 256)          41728       dropout_139[0][0]                
__________________________________________________________________________________________________
lstm_70 (LSTM)                  (None, 256)          525312      dropout_140[0][0]                
__________________________________________________________________________________________________
add_70 (Add)                    (None, 256)          0           dense_208[0][0]                  
                                                                 lstm_70[0][0]                    
__________________________________________________________________________________________________
dense_209 (Dense)               (None, 256)          65792       add_70[0][0]                     
__________________________________________________________________________________________________
dense_210 (Dense)               (None, 932)          239524      dense_209[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.29177, saving model to model-ep001-loss4.124-val_loss2.292.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.29177 to 1.56378, saving model to model-ep002-loss2.534-val_loss1.564.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.56378 to 1.38886, saving model to model-ep003-loss2.065-val_loss1.389.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.38886 to 1.35984, saving model to model-ep004-loss1.815-val_loss1.360.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.35984 to 1.27268, saving model to model-ep005-loss1.633-val_loss1.273.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.27268 to 1.24662, saving model to model-ep006-loss1.488-val_loss1.247.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 1.24662
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.24662
Epoch 9/10

Epoch 00009: val_loss improved from 1.24662 to 1.24494, saving model to model-ep009-loss1.130-val_loss1.245.h5
Epoch 10/10

Epoch 00010: val_loss improved from 1.24494 to 1.23487, saving model to model-ep010-loss1.023-val_loss1.235.h5
model-ep010-loss1.023-val_loss1.235.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.599583
BLEU-2: 0.449953
BLEU-3: 0.397707
BLEU-4: 0.296981
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_142 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_141 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_71 (Embedding)        (None, 246, 256)     238592      input_142[0][0]                  
__________________________________________________________________________________________________
dropout_141 (Dropout)           (None, 162)          0           input_141[0][0]                  
__________________________________________________________________________________________________
dropout_142 (Dropout)           (None, 246, 256)     0           embedding_71[0][0]               
__________________________________________________________________________________________________
dense_211 (Dense)               (None, 256)          41728       dropout_141[0][0]                
__________________________________________________________________________________________________
lstm_71 (LSTM)                  (None, 256)          525312      dropout_142[0][0]                
__________________________________________________________________________________________________
add_71 (Add)                    (None, 256)          0           dense_211[0][0]                  
                                                                 lstm_71[0][0]                    
__________________________________________________________________________________________________
dense_212 (Dense)               (None, 256)          65792       add_71[0][0]                     
__________________________________________________________________________________________________
dense_213 (Dense)               (None, 932)          239524      dense_212[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.70176, saving model to model-ep001-loss4.143-val_loss3.702.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.70176 to 3.19957, saving model to model-ep002-loss2.537-val_loss3.200.h5
Epoch 3/10

Epoch 00003: val_loss improved from 3.19957 to 3.13127, saving model to model-ep003-loss2.076-val_loss3.131.h5
Epoch 4/10

Epoch 00004: val_loss improved from 3.13127 to 3.02850, saving model to model-ep004-loss1.826-val_loss3.029.h5
Epoch 5/10

Epoch 00005: val_loss improved from 3.02850 to 2.99342, saving model to model-ep005-loss1.644-val_loss2.993.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.99342
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.99342
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.99342
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.99342
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.99342
model-ep005-loss1.644-val_loss2.993.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.583948
BLEU-2: 0.443772
BLEU-3: 0.393085
BLEU-4: 0.295385
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_144 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_143 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_72 (Embedding)        (None, 246, 256)     238592      input_144[0][0]                  
__________________________________________________________________________________________________
dropout_143 (Dropout)           (None, 162)          0           input_143[0][0]                  
__________________________________________________________________________________________________
dropout_144 (Dropout)           (None, 246, 256)     0           embedding_72[0][0]               
__________________________________________________________________________________________________
dense_214 (Dense)               (None, 256)          41728       dropout_143[0][0]                
__________________________________________________________________________________________________
lstm_72 (LSTM)                  (None, 256)          525312      dropout_144[0][0]                
__________________________________________________________________________________________________
add_72 (Add)                    (None, 256)          0           dense_214[0][0]                  
                                                                 lstm_72[0][0]                    
__________________________________________________________________________________________________
dense_215 (Dense)               (None, 256)          65792       add_72[0][0]                     
__________________________________________________________________________________________________
dense_216 (Dense)               (None, 932)          239524      dense_215[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.47737, saving model to model-ep001-loss4.163-val_loss2.477.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.47737 to 1.87954, saving model to model-ep002-loss2.613-val_loss1.880.h5
Epoch 3/10

Epoch 00003: val_loss improved from 1.87954 to 1.70809, saving model to model-ep003-loss2.123-val_loss1.708.h5
Epoch 4/10

Epoch 00004: val_loss improved from 1.70809 to 1.56696, saving model to model-ep004-loss1.873-val_loss1.567.h5
Epoch 5/10

Epoch 00005: val_loss improved from 1.56696 to 1.51645, saving model to model-ep005-loss1.683-val_loss1.516.h5
Epoch 6/10

Epoch 00006: val_loss improved from 1.51645 to 1.47848, saving model to model-ep006-loss1.541-val_loss1.478.h5
Epoch 7/10

Epoch 00007: val_loss improved from 1.47848 to 1.40403, saving model to model-ep007-loss1.414-val_loss1.404.h5
Epoch 8/10

Epoch 00008: val_loss did not improve from 1.40403
Epoch 9/10

Epoch 00009: val_loss did not improve from 1.40403
Epoch 10/10

Epoch 00010: val_loss did not improve from 1.40403
model-ep007-loss1.414-val_loss1.404.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.536193
BLEU-2: 0.404776
BLEU-3: 0.355063
BLEU-4: 0.269855
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_146 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_145 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_73 (Embedding)        (None, 246, 256)     238592      input_146[0][0]                  
__________________________________________________________________________________________________
dropout_145 (Dropout)           (None, 162)          0           input_145[0][0]                  
__________________________________________________________________________________________________
dropout_146 (Dropout)           (None, 246, 256)     0           embedding_73[0][0]               
__________________________________________________________________________________________________
dense_217 (Dense)               (None, 256)          41728       dropout_145[0][0]                
__________________________________________________________________________________________________
lstm_73 (LSTM)                  (None, 256)          525312      dropout_146[0][0]                
__________________________________________________________________________________________________
add_73 (Add)                    (None, 256)          0           dense_217[0][0]                  
                                                                 lstm_73[0][0]                    
__________________________________________________________________________________________________
dense_218 (Dense)               (None, 256)          65792       add_73[0][0]                     
__________________________________________________________________________________________________
dense_219 (Dense)               (None, 932)          239524      dense_218[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 3.35792, saving model to model-ep001-loss4.139-val_loss3.358.h5
Epoch 2/10

Epoch 00002: val_loss improved from 3.35792 to 2.86487, saving model to model-ep002-loss2.535-val_loss2.865.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.86487 to 2.74598, saving model to model-ep003-loss2.073-val_loss2.746.h5
Epoch 4/10

Epoch 00004: val_loss did not improve from 2.74598
Epoch 5/10

Epoch 00005: val_loss improved from 2.74598 to 2.74593, saving model to model-ep005-loss1.645-val_loss2.746.h5
Epoch 6/10

Epoch 00006: val_loss did not improve from 2.74593
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.74593
Epoch 8/10

Epoch 00008: val_loss did not improve from 2.74593
Epoch 9/10

Epoch 00009: val_loss did not improve from 2.74593
Epoch 10/10

Epoch 00010: val_loss did not improve from 2.74593
model-ep005-loss1.645-val_loss2.746.h5
1 / 255
2 / 255
3 / 255
4 / 255
5 / 255
6 / 255
7 / 255
8 / 255
9 / 255
10 / 255
11 / 255
12 / 255
13 / 255
14 / 255
15 / 255
16 / 255
17 / 255
18 / 255
19 / 255
20 / 255
21 / 255
22 / 255
23 / 255
24 / 255
25 / 255
26 / 255
27 / 255
28 / 255
29 / 255
30 / 255
31 / 255
32 / 255
33 / 255
34 / 255
35 / 255
36 / 255
37 / 255
38 / 255
39 / 255
40 / 255
41 / 255
42 / 255
43 / 255
44 / 255
45 / 255
46 / 255
47 / 255
48 / 255
49 / 255
50 / 255
51 / 255
52 / 255
53 / 255
54 / 255
55 / 255
56 / 255
57 / 255
58 / 255
59 / 255
60 / 255
61 / 255
62 / 255
63 / 255
64 / 255
65 / 255
66 / 255
67 / 255
68 / 255
69 / 255
70 / 255
71 / 255
72 / 255
73 / 255
74 / 255
75 / 255
76 / 255
77 / 255
78 / 255
79 / 255
80 / 255
81 / 255
82 / 255
83 / 255
84 / 255
85 / 255
86 / 255
87 / 255
88 / 255
89 / 255
90 / 255
91 / 255
92 / 255
93 / 255
94 / 255
95 / 255
96 / 255
97 / 255
98 / 255
99 / 255
100 / 255
101 / 255
102 / 255
103 / 255
104 / 255
105 / 255
106 / 255
107 / 255
108 / 255
109 / 255
110 / 255
111 / 255
112 / 255
113 / 255
114 / 255
115 / 255
116 / 255
117 / 255
118 / 255
119 / 255
120 / 255
121 / 255
122 / 255
123 / 255
124 / 255
125 / 255
126 / 255
127 / 255
128 / 255
129 / 255
130 / 255
131 / 255
132 / 255
133 / 255
134 / 255
135 / 255
136 / 255
137 / 255
138 / 255
139 / 255
140 / 255
141 / 255
142 / 255
143 / 255
144 / 255
145 / 255
146 / 255
147 / 255
148 / 255
149 / 255
150 / 255
151 / 255
152 / 255
153 / 255
154 / 255
155 / 255
156 / 255
157 / 255
158 / 255
159 / 255
160 / 255
161 / 255
162 / 255
163 / 255
164 / 255
165 / 255
166 / 255
167 / 255
168 / 255
169 / 255
170 / 255
171 / 255
172 / 255
173 / 255
174 / 255
175 / 255
176 / 255
177 / 255
178 / 255
179 / 255
180 / 255
181 / 255
182 / 255
183 / 255
184 / 255
185 / 255
186 / 255
187 / 255
188 / 255
189 / 255
190 / 255
191 / 255
192 / 255
193 / 255
194 / 255
195 / 255
196 / 255
197 / 255
198 / 255
199 / 255
200 / 255
201 / 255
202 / 255
203 / 255
204 / 255
205 / 255
206 / 255
207 / 255
208 / 255
209 / 255
210 / 255
211 / 255
212 / 255
213 / 255
214 / 255
215 / 255
216 / 255
217 / 255
218 / 255
219 / 255
220 / 255
221 / 255
222 / 255
223 / 255
224 / 255
225 / 255
226 / 255
227 / 255
228 / 255
229 / 255
230 / 255
231 / 255
232 / 255
233 / 255
234 / 255
235 / 255
236 / 255
237 / 255
238 / 255
239 / 255
240 / 255
241 / 255
242 / 255
243 / 255
244 / 255
245 / 255
246 / 255
247 / 255
248 / 255
249 / 255
250 / 255
251 / 255
252 / 255
253 / 255
254 / 255
255 / 255
BLEU-1: 0.594142
BLEU-2: 0.450328
BLEU-3: 0.400408
BLEU-4: 0.306132
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_148 (InputLayer)          (None, 246)          0                                            
__________________________________________________________________________________________________
input_147 (InputLayer)          (None, 162)          0                                            
__________________________________________________________________________________________________
embedding_74 (Embedding)        (None, 246, 256)     238592      input_148[0][0]                  
__________________________________________________________________________________________________
dropout_147 (Dropout)           (None, 162)          0           input_147[0][0]                  
__________________________________________________________________________________________________
dropout_148 (Dropout)           (None, 246, 256)     0           embedding_74[0][0]               
__________________________________________________________________________________________________
dense_220 (Dense)               (None, 256)          41728       dropout_147[0][0]                
__________________________________________________________________________________________________
lstm_74 (LSTM)                  (None, 256)          525312      dropout_148[0][0]                
__________________________________________________________________________________________________
add_74 (Add)                    (None, 256)          0           dense_220[0][0]                  
                                                                 lstm_74[0][0]                    
__________________________________________________________________________________________________
dense_221 (Dense)               (None, 256)          65792       add_74[0][0]                     
__________________________________________________________________________________________________
dense_222 (Dense)               (None, 932)          239524      dense_221[0][0]                  
==================================================================================================
Total params: 1,110,948
Trainable params: 1,110,948
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 26635 samples, validate on 269 samples
Epoch 1/10

Epoch 00001: val_loss improved from inf to 2.84499, saving model to model-ep001-loss4.142-val_loss2.845.h5
Epoch 2/10

Epoch 00002: val_loss improved from 2.84499 to 2.34796, saving model to model-ep002-loss2.499-val_loss2.348.h5
Epoch 3/10

Epoch 00003: val_loss improved from 2.34796 to 2.19035, saving model to model-ep003-loss2.030-val_loss2.190.h5
Epoch 4/10

Epoch 00004: val_loss did not improve from 2.19035
Epoch 5/10

Epoch 00005: val_loss improved from 2.19035 to 2.18444, saving model to model-ep005-loss1.607-val_loss2.184.h5
Epoch 6/10

Epoch 00006: val_loss improved from 2.18444 to 2.15164, saving model to model-ep006-loss1.456-val_loss2.152.h5
Epoch 7/10

Epoch 00007: val_loss did not improve from 2.15164
Epoch 8/10
